use bytes::BufMut;
use std::fmt::Debug;
use std::sync::atomic::{AtomicBool, AtomicU16, AtomicU32, AtomicUsize, Ordering};
use std::{collections::HashMap, net::SocketAddr, pin::Pin, sync::Arc, time::Duration};
use tokio::io::{AsyncRead, AsyncWrite};
use tokio::net::TcpStream;
use tokio::sync::mpsc;
use tracing::{debug, error, info, warn};

use crate::{
    current_timestamp,
    registry::{GossipRegistry, RegistryMessage},
    GossipError, Result,
};

// ==== SINGLE SOURCE OF TRUTH FOR ALL BUFFER SIZES ====
// THIS is the ONLY place we define the master buffer size!
// Change this ONE constant to adjust ALL buffer behavior system-wide.
pub const MASTER_BUFFER_SIZE: usize = 1024 * 1024; // 1MB - THE source of truth

// All other buffer sizes derive from the master constant - NO MAGIC NUMBERS!
pub const TCP_BUFFER_SIZE: usize = MASTER_BUFFER_SIZE; // BufWriter & io_uring buffer
pub const STREAM_CHUNK_SIZE: usize = MASTER_BUFFER_SIZE; // Streaming chunk size
pub const STREAMING_THRESHOLD: usize = MASTER_BUFFER_SIZE.saturating_sub(1024); // Just under buffer limit

// Ring buffer configuration (NUMBER OF SLOTS, not bytes!)
pub const RING_BUFFER_SLOTS: usize = 1024; // Number of WriteCommand slots in ring buffer
                                           // Note: Each slot can hold any size message - this is NOT a byte limit
                                           // Note: Streaming threshold ensures messages fit within TCP_BUFFER_SIZE

/// Buffer configuration that encapsulates all buffer-related settings
///
/// This struct ensures that the streaming threshold is always derived from the actual buffer size,
/// preventing the disconnection between buffer size and streaming decisions that causes message loss.
#[derive(Debug, Clone)]
pub struct BufferConfig {
    ring_buffer_slots: usize, // Number of message slots in ring buffer
    tcp_buffer_size: usize,   // Size in bytes for TCP buffers
}

impl BufferConfig {
    /// Create a new BufferConfig with validation
    ///
    /// # Arguments
    /// * `tcp_buffer_size` - The size of TCP buffers in bytes
    ///
    /// # Errors
    /// Returns an error if the buffer size is less than 256KB for safety
    pub fn new(tcp_buffer_size: usize) -> Result<Self> {
        // Enforce minimum size of 256KB for safety
        if tcp_buffer_size < 256 * 1024 {
            return Err(GossipError::InvalidConfig(format!(
                "TCP buffer must be at least 256KB, got {}KB",
                tcp_buffer_size / 1024
            )));
        }
        Ok(Self {
            ring_buffer_slots: RING_BUFFER_SLOTS, // Use constant for slots
            tcp_buffer_size,
        })
    }

    /// Get the ring buffer slot count (NOT bytes!)
    pub fn ring_buffer_slots(&self) -> usize {
        self.ring_buffer_slots
    }

    /// Calculate the streaming threshold based on buffer size
    ///
    /// The streaming threshold is always derived from the buffer size,
    /// leaving 1KB headroom for headers and serialization overhead.
    pub fn streaming_threshold(&self) -> usize {
        // Always derive from buffer size
        // Leave 1KB headroom for headers/overhead
        self.tcp_buffer_size.saturating_sub(1024)
    }

    /// Get the TCP buffer size for BufWriter and io_uring
    ///
    /// This ensures TCP buffers match the configured size, preventing bottlenecks.
    pub fn tcp_buffer_size(&self) -> usize {
        self.tcp_buffer_size
    }

    /// Create BufferConfig using the master buffer size (recommended)
    pub fn from_master() -> Self {
        Self {
            ring_buffer_slots: RING_BUFFER_SLOTS,
            tcp_buffer_size: MASTER_BUFFER_SIZE,
        }
    }

    /// Create a default BufferConfig with master buffer size
    pub fn default() -> Self {
        // Use master constant instead of magic number!
        Self {
            ring_buffer_slots: RING_BUFFER_SLOTS,
            tcp_buffer_size: MASTER_BUFFER_SIZE,
        }
    }
}

/// Stream frame types for high-performance streaming protocol
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u8)]
pub enum StreamFrameType {
    Data = 0x01,
    Ack = 0x02,
    Close = 0x03,
    Heartbeat = 0x04,
    TellAsk = 0x05,    // Regular tell/ask messages
    StreamData = 0x06, // Dedicated streaming data
}

/// Channel IDs for stream multiplexing
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u8)]
pub enum ChannelId {
    TellAsk = 0x00,  // Regular tell/ask channel
    Stream1 = 0x01,  // Dedicated streaming channel 1
    Stream2 = 0x02,  // Dedicated streaming channel 2
    Stream3 = 0x03,  // Dedicated streaming channel 3
    Bulk = 0x04,     // Bulk data channel
    Priority = 0x05, // Priority streaming channel
    Global = 0xFF,   // Global channel for all operations
}

/// Stream frame flags
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u8)]
pub enum StreamFrameFlags {
    None = 0x00,
    More = 0x01,       // More frames to follow
    Compressed = 0x02, // Frame is compressed
    Encrypted = 0x04,  // Frame is encrypted
}

/// Stream frame header for structured messaging
#[derive(Debug, Clone, Copy, rkyv::Archive, rkyv::Serialize, rkyv::Deserialize)]
#[rkyv(derive(Debug))]
pub struct StreamFrameHeader {
    pub frame_type: u8,
    pub channel_id: u8,
    pub flags: u8,
    pub sequence_id: u16,
    pub payload_len: u32,
}

/// Lock-free connection state representation
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u32)]
pub enum ConnectionState {
    Disconnected = 0,
    Connecting = 1,
    Connected = 2,
    Failed = 3,
}

impl From<u32> for ConnectionState {
    fn from(value: u32) -> Self {
        match value {
            0 => ConnectionState::Disconnected,
            1 => ConnectionState::Connecting,
            2 => ConnectionState::Connected,
            3 => ConnectionState::Failed,
            _ => ConnectionState::Failed,
        }
    }
}

/// Lock-free connection metadata
#[derive(Debug)]
pub struct LockFreeConnection {
    pub addr: SocketAddr,
    pub state: AtomicU32,       // ConnectionState
    pub last_used: AtomicUsize, // Timestamp
    pub bytes_written: AtomicUsize,
    pub bytes_read: AtomicUsize,
    pub failure_count: AtomicUsize,
    pub stream_handle: Option<Arc<LockFreeStreamHandle>>,
    pub(crate) correlation: Option<Arc<CorrelationTracker>>,
}

impl Clone for LockFreeConnection {
    fn clone(&self) -> Self {
        Self {
            addr: self.addr,
            state: AtomicU32::new(self.state.load(Ordering::Relaxed)),
            last_used: AtomicUsize::new(self.last_used.load(Ordering::Relaxed)),
            bytes_written: AtomicUsize::new(self.bytes_written.load(Ordering::Relaxed)),
            bytes_read: AtomicUsize::new(self.bytes_read.load(Ordering::Relaxed)),
            failure_count: AtomicUsize::new(self.failure_count.load(Ordering::Relaxed)),
            stream_handle: self.stream_handle.clone(),
            correlation: self.correlation.clone(),
        }
    }
}

impl LockFreeConnection {
    pub fn new(addr: SocketAddr) -> Self {
        Self {
            addr,
            state: AtomicU32::new(ConnectionState::Disconnected as u32),
            last_used: AtomicUsize::new(0),
            bytes_written: AtomicUsize::new(0),
            bytes_read: AtomicUsize::new(0),
            failure_count: AtomicUsize::new(0),
            stream_handle: None,
            correlation: Some(CorrelationTracker::new()),
        }
    }

    pub fn get_state(&self) -> ConnectionState {
        self.state.load(Ordering::Acquire).into()
    }

    pub fn set_state(&self, state: ConnectionState) {
        self.state.store(state as u32, Ordering::Release);
    }

    pub fn try_set_state(&self, expected: ConnectionState, new: ConnectionState) -> bool {
        self.state
            .compare_exchange(
                expected as u32,
                new as u32,
                Ordering::AcqRel,
                Ordering::Acquire,
            )
            .is_ok()
    }

    pub fn update_last_used(&self) {
        self.last_used
            .store(crate::current_timestamp() as usize, Ordering::Release);
    }

    pub fn increment_failure_count(&self) -> usize {
        self.failure_count.fetch_add(1, Ordering::AcqRel)
    }

    pub fn reset_failure_count(&self) {
        self.failure_count.store(0, Ordering::Release);
    }

    pub fn is_connected(&self) -> bool {
        self.get_state() == ConnectionState::Connected
    }

    pub fn is_failed(&self) -> bool {
        self.get_state() == ConnectionState::Failed
    }
}

/// Write command for the lock-free ring buffer with zero-copy optimization
#[derive(Debug, Clone)]
pub struct WriteCommand {
    pub channel_id: ChannelId,
    pub data: bytes::Bytes,
    pub sequence: u64,
}

/// Zero-copy write command that references pre-allocated buffer slots
#[derive(Debug)]
pub struct ZeroCopyWriteCommand {
    pub channel_id: ChannelId,
    pub buffer_ptr: *const u8,
    pub len: usize,
    pub sequence: u64,
    pub buffer_id: usize, // For buffer pool management
}

// Safety: ZeroCopyWriteCommand is only used within the single writer task
unsafe impl Send for ZeroCopyWriteCommand {}
unsafe impl Sync for ZeroCopyWriteCommand {}

/// Memory pool for zero-allocation message handling
#[derive(Debug)]
pub struct MessageBufferPool {
    pool: Vec<Vec<u8>>,
    pool_size: usize,
    available_buffers: AtomicUsize,
    next_buffer_idx: AtomicUsize,
}

impl MessageBufferPool {
    pub fn new(pool_size: usize, buffer_size: usize) -> Self {
        let mut pool = Vec::with_capacity(pool_size);
        for _ in 0..pool_size {
            pool.push(Vec::with_capacity(buffer_size));
        }

        Self {
            pool,
            pool_size,
            available_buffers: AtomicUsize::new(pool_size),
            next_buffer_idx: AtomicUsize::new(0),
        }
    }

    /// Get a buffer from the pool - returns None if pool is empty
    pub fn get_buffer(&self) -> Option<Vec<u8>> {
        let available = self.available_buffers.load(Ordering::Acquire);
        if available == 0 {
            return None;
        }

        let idx = self.next_buffer_idx.fetch_add(1, Ordering::AcqRel) % self.pool_size;

        // Try to claim this buffer
        if self.available_buffers.fetch_sub(1, Ordering::AcqRel) > 0 {
            // We successfully claimed a buffer
            unsafe {
                let buffer_ptr = self.pool.as_ptr().add(idx) as *mut Vec<u8>;
                let mut buffer = std::ptr::replace(buffer_ptr, Vec::new());
                buffer.clear(); // Reset length but keep capacity
                Some(buffer)
            }
        } else {
            // No buffers available, restore count
            self.available_buffers.fetch_add(1, Ordering::Release);
            None
        }
    }

    /// Return a buffer to the pool
    pub fn return_buffer(&self, mut buffer: Vec<u8>) {
        buffer.clear(); // Reset length but keep capacity

        let idx = self.next_buffer_idx.fetch_add(1, Ordering::AcqRel) % self.pool_size;

        unsafe {
            let buffer_ptr = self.pool.as_ptr().add(idx) as *mut Vec<u8>;
            *buffer_ptr = buffer;
        }

        self.available_buffers.fetch_add(1, Ordering::Release);
    }

    pub fn available_count(&self) -> usize {
        self.available_buffers.load(Ordering::Acquire)
    }

    pub fn is_empty(&self) -> bool {
        self.available_count() == 0
    }
}

/// Lock-free ring buffer for high-performance writes with proper memory ordering
#[derive(Debug)]
pub struct LockFreeRingBuffer {
    buffer: Vec<Option<WriteCommand>>,
    capacity: usize,
    // Cache-line aligned atomic counters to prevent false sharing
    write_index: AtomicUsize,
    read_index: AtomicUsize,
    pending_writes: AtomicUsize,
}

impl LockFreeRingBuffer {
    pub fn new(capacity: usize) -> Self {
        Self {
            buffer: (0..capacity).map(|_| None).collect(),
            capacity,
            write_index: AtomicUsize::new(0),
            read_index: AtomicUsize::new(0),
            pending_writes: AtomicUsize::new(0),
        }
    }

    /// Try to push a write command - returns true if successful
    /// Uses proper memory ordering to prevent ABA problem
    pub fn try_push(&self, command: WriteCommand) -> bool {
        let current_writes = self.pending_writes.load(Ordering::Acquire);
        if current_writes >= self.capacity {
            return false; // Buffer full
        }

        let write_idx = self.write_index.fetch_add(1, Ordering::AcqRel) % self.capacity;

        // This is unsafe but fast - we're assuming single writer per slot
        // Using proper memory ordering ensures visibility across cores
        unsafe {
            let slot = self.buffer.as_ptr().add(write_idx) as *mut Option<WriteCommand>;
            *slot = Some(command);
        }

        // Release ordering ensures the write above is visible before incrementing pending count
        self.pending_writes.fetch_add(1, Ordering::Release);
        true
    }

    /// Try to pop a write command - returns None if empty
    /// Uses proper memory ordering to prevent race conditions
    pub fn try_pop(&self) -> Option<WriteCommand> {
        let current_writes = self.pending_writes.load(Ordering::Acquire);
        if current_writes == 0 {
            return None;
        }

        let read_idx = self.read_index.fetch_add(1, Ordering::AcqRel) % self.capacity;

        // This is unsafe but fast - we're assuming single reader per slot
        // Using proper memory ordering ensures we see writes from other cores
        unsafe {
            let slot = self.buffer.as_ptr().add(read_idx) as *mut Option<WriteCommand>;
            let command = (*slot).take();
            if command.is_some() {
                // Release ordering ensures the slot is cleared before decrementing pending count
                self.pending_writes.fetch_sub(1, Ordering::Release);
            }
            command
        }
    }

    pub fn pending_count(&self) -> usize {
        self.pending_writes.load(Ordering::Acquire)
    }

    /// Get buffer utilization as a percentage (0-100)
    pub fn utilization(&self) -> f32 {
        (self.pending_count() as f32 / self.capacity as f32) * 100.0
    }

    /// Check if buffer is nearly full (>90% capacity)
    pub fn is_nearly_full(&self) -> bool {
        self.pending_count() > (self.capacity * 9) / 10
    }
}

/// Vectored write command for zero-copy header + payload operations
#[derive(Debug)]
pub struct VectoredWriteCommand {
    header: bytes::Bytes,
    payload: bytes::Bytes,
}

/// Commands for streaming operations
#[derive(Debug)]
enum StreamingCommand {
    /// Direct write bytes for streaming
    WriteBytes(bytes::Bytes),
    /// Flush the writer
    Flush,
    /// Vectored write for header + payload (zero-copy)
    VectoredWrite(VectoredWriteCommand),
    /// Batch of owned chunks for streaming (zero-copy)
    OwnedChunks(Vec<bytes::Bytes>),
}

/// Truly lock-free streaming handle with dedicated background writer
#[derive(Clone)]
pub struct LockFreeStreamHandle {
    addr: SocketAddr,
    channel_id: ChannelId,
    sequence_counter: Arc<AtomicUsize>,
    bytes_written: Arc<AtomicUsize>, // This tracks actual TCP bytes written
    ring_buffer: Arc<LockFreeRingBuffer>,
    shutdown_signal: Arc<AtomicBool>,
    /// Atomic flag for coordinating streaming mode
    streaming_active: Arc<AtomicBool>,
    /// Channel to send streaming commands to background task
    streaming_tx: mpsc::UnboundedSender<StreamingCommand>,
    /// Buffer configuration that determines sizes and thresholds
    buffer_config: BufferConfig,
}

impl LockFreeStreamHandle {
    /// Create a new lock-free streaming handle with background writer task
    pub fn new<W>(
        tcp_writer: W,
        addr: SocketAddr,
        channel_id: ChannelId,
        buffer_config: BufferConfig,
    ) -> Self
    where
        W: AsyncWrite + Unpin + Send + 'static,
    {
        let ring_buffer = Arc::new(LockFreeRingBuffer::new(buffer_config.ring_buffer_slots()));
        let shutdown_signal = Arc::new(AtomicBool::new(false));
        let streaming_active = Arc::new(AtomicBool::new(false));

        // Create shared counter for actual TCP bytes written
        let bytes_written = Arc::new(AtomicUsize::new(0));

        // Create channel for streaming commands
        let (streaming_tx, streaming_rx) = mpsc::unbounded_channel();

        // Spawn background writer task with exclusive TCP access - NO MUTEX!
        {
            let ring_buffer = ring_buffer.clone();
            let shutdown_signal = shutdown_signal.clone();
            let bytes_written_for_task = bytes_written.clone();
            let streaming_active_for_task = streaming_active.clone();

            tokio::spawn(async move {
                Self::background_writer_task(
                    tcp_writer, // Writer half
                    ring_buffer,
                    shutdown_signal,
                    bytes_written_for_task,
                    streaming_active_for_task,
                    streaming_rx,
                )
                .await;
            });
        }

        Self {
            addr,
            channel_id,
            sequence_counter: Arc::new(AtomicUsize::new(0)),
            bytes_written, // This now tracks actual TCP bytes written
            ring_buffer,
            shutdown_signal,
            streaming_active,
            streaming_tx,
            buffer_config,
        }
    }

    /// Background writer task - truly lock-free with exclusive TCP access
    /// OPTIMIZED FOR MAXIMUM THROUGHPUT - NO MUTEX NEEDED!
    async fn background_writer_task<W>(
        tcp_writer: W,
        ring_buffer: Arc<LockFreeRingBuffer>,
        shutdown_signal: Arc<AtomicBool>,
        bytes_written_counter: Arc<AtomicUsize>, // Track ALL bytes written to TCP
        streaming_active: Arc<AtomicBool>,
        mut streaming_rx: mpsc::UnboundedReceiver<StreamingCommand>,
    ) where
        W: AsyncWrite + Unpin + Send + 'static,
    {
        use std::io::IoSlice;
        use tokio::io::AsyncWriteExt;

        // Use direct tokio writer with vectored I/O for now
        // TODO: Integrate platform-specific writers (io_uring on Linux 5.1+)
        // This requires either:
        // 1. Modifying StreamWriter trait to work with OwnedWriteHalf
        // 2. Or using a different socket splitting approach that allows io_uring
        // Use full TCP buffer size for large messages (CRITICAL FIX!)
        // Need large buffer to handle 100KB+ BacktestSummary messages
        let mut writer = tokio::io::BufWriter::with_capacity(TCP_BUFFER_SIZE, tcp_writer);

        // Smaller batches for lower latency
        const RING_BATCH_SIZE: usize = 64; // Smaller batches for faster processing
        const FLUSH_THRESHOLD: usize = 4 * 1024; // 4KB before flush (much lower for ask/reply)

        let mut bytes_since_flush = 0;

        while !shutdown_signal.load(Ordering::Relaxed) {
            let mut total_bytes_written = 0;

            // Check for streaming commands first (priority over ring buffer)
            tokio::select! {
                Some(cmd) = streaming_rx.recv() => {
                    match cmd {
                        StreamingCommand::WriteBytes(data) => {
                            match writer.write_all(&data).await {
                                Ok(_) => {
                                    bytes_written_counter.fetch_add(data.len(), Ordering::Relaxed);
                                    total_bytes_written += data.len();
                                }
                                Err(e) => {
                                    error!("Streaming write error: {}", e);
                                    break;
                                }
                            }
                        }
                        StreamingCommand::Flush => {
                            let _ = writer.flush().await;
                        }
                        StreamingCommand::VectoredWrite(cmd) => {
                            // Zero-copy vectored I/O - header + payload in single syscall
                            use tokio::io::AsyncWriteExt;
                            let header_slice = std::io::IoSlice::new(&cmd.header);
                            let payload_slice = std::io::IoSlice::new(&cmd.payload);
                            let bufs = &[header_slice, payload_slice];

                            match writer.write_vectored(bufs).await {
                                Ok(n) => {
                                    bytes_written_counter.fetch_add(n, Ordering::Relaxed);
                                    total_bytes_written += n;
                                }
                                Err(e) => {
                                    error!("Vectored write error: {}", e);
                                    break;
                                }
                            }
                        }
                        StreamingCommand::OwnedChunks(chunks) => {
                            // Batch vectored write for multiple chunks
                            use tokio::io::AsyncWriteExt;
                            let slices: Vec<std::io::IoSlice> = chunks.iter()
                                .map(|chunk| std::io::IoSlice::new(chunk))
                                .collect();

                            match writer.write_vectored(&slices).await {
                                Ok(n) => {
                                    bytes_written_counter.fetch_add(n, Ordering::Relaxed);
                                    total_bytes_written += n;
                                }
                                Err(e) => {
                                    error!("Chunk batch write error: {}", e);
                                    break;
                                }
                            }
                        }
                    }
                }
                // Poll ring buffer immediately without sleep for low latency
                _ = tokio::task::yield_now() => {
                    // Check if streaming is active - if so, skip ring buffer processing
                    if streaming_active.load(Ordering::Acquire) {
                        continue;
                    }

                    // Process ring buffer writes with LARGE batches
                    let mut io_slices = Vec::with_capacity(RING_BATCH_SIZE);
                    let mut write_data = Vec::with_capacity(RING_BATCH_SIZE);

                    // Try to pop messages immediately for low latency
                    for _ in 0..RING_BATCH_SIZE {
                        if let Some(command) = ring_buffer.try_pop() {
                            write_data.push(command.data);
                        } else {
                            break;
                        }
                    }

                    if !write_data.is_empty() {
                        // Create IoSlice array for vectored write
                        for data in &write_data {
                            io_slices.push(IoSlice::new(data));
                        }

                        // Use vectored I/O for efficient batch writing
                        match writer.write_vectored(&io_slices).await {
                            Ok(bytes_written) => {
                                bytes_written_counter.fetch_add(bytes_written, Ordering::Relaxed);
                                total_bytes_written += bytes_written;
                            }
                            Err(_e) => {
                                // Connection probably broken, exit task
                                break;
                            }
                        }
                    }
                }
            }

            bytes_since_flush += total_bytes_written;

            // Only flush when we've written enough data or no more work
            if bytes_since_flush >= FLUSH_THRESHOLD || total_bytes_written == 0 {
                let _ = writer.flush().await;
                bytes_since_flush = 0;

                // If no work was done, wait briefly before next iteration
                if total_bytes_written == 0 {
                    tokio::task::yield_now().await;
                }
            }
        }
    }

    /// Write data to the lock-free ring buffer - NO BLOCKING
    /// DEPRECATED: Use send_bytes_zero_copy instead to avoid copying
    // pub fn write_nonblocking(&self, data: &[u8]) -> Result<()> {
    //     // TODO: This still copies data - need to migrate all callers to send_bytes_zero_copy
    //     warn!("DEPRECATED: write_nonblocking called - should use send_bytes_zero_copy");
    //     self.write_bytes_nonblocking(bytes::Bytes::copy_from_slice(data))
    // }

    /// Write Bytes to the lock-free ring buffer - NO BLOCKING, NO COPY
    pub fn write_bytes_nonblocking(&self, data: bytes::Bytes) -> Result<()> {
        let sequence = self.sequence_counter.fetch_add(1, Ordering::Relaxed);

        let command = WriteCommand {
            channel_id: self.channel_id,
            data: data.clone(),
            sequence: sequence as u64,
        };

        if self.ring_buffer.try_push(command) {
            // Don't increment bytes_written here - only increment when actually written to TCP
            Ok(())
        } else {
            // Ring buffer full - drop the data (fire and forget)
            Ok(())
        }
    }

    /// Flush the writer immediately - used for low-latency ask operations
    pub fn flush_immediately(&self) -> Result<()> {
        // Send a flush command to the writer task
        self.streaming_tx
            .send(StreamingCommand::Flush)
            .map_err(|_| GossipError::Shutdown)
    }

    /// Write data with vectored batching - still no blocking
    pub fn write_vectored_nonblocking(&self, data_chunks: &[&[u8]]) -> Result<()> {
        if data_chunks.is_empty() {
            return Ok(());
        }

        // Use BytesMut for efficient concatenation
        let total_len: usize = data_chunks.iter().map(|chunk| chunk.len()).sum();
        let mut combined_buffer = bytes::BytesMut::with_capacity(total_len);

        for chunk in data_chunks {
            combined_buffer.extend_from_slice(chunk);
        }

        self.write_bytes_nonblocking(combined_buffer.freeze())
    }

    /// Write large data in chunks to avoid blocking
    pub fn write_chunked_nonblocking(&self, data: &[u8], chunk_size: usize) -> Result<()> {
        if data.is_empty() {
            return Ok(());
        }

        for chunk in data.chunks(chunk_size) {
            let _ = self.write_bytes_nonblocking(bytes::Bytes::copy_from_slice(chunk));
        }

        Ok(())
    }

    /// Get ring buffer status
    pub fn buffer_status(&self) -> (usize, usize) {
        let pending = self.ring_buffer.pending_count();
        (pending, self.ring_buffer.capacity - pending)
    }

    /// Check if ring buffer is near capacity
    pub fn is_buffer_full(&self) -> bool {
        self.ring_buffer.pending_count() >= (self.ring_buffer.capacity * 9 / 10)
        // 90% full
    }

    /// Get channel ID
    pub fn channel_id(&self) -> ChannelId {
        self.channel_id
    }

    /// Get total bytes written
    pub fn bytes_written(&self) -> usize {
        self.bytes_written.load(Ordering::Relaxed)
    }

    /// Get sequence counter
    pub fn sequence_number(&self) -> usize {
        self.sequence_counter.load(Ordering::Relaxed)
    }

    /// Get socket address
    pub fn addr(&self) -> SocketAddr {
        self.addr
    }

    /// Shutdown the background writer task
    pub fn shutdown(&self) {
        self.shutdown_signal.store(true, Ordering::Relaxed);
    }

    /// Get the streaming threshold for this connection
    ///
    /// Returns the threshold above which messages should be streamed rather than
    /// sent through the ring buffer. This is always derived from the buffer size.
    pub fn streaming_threshold(&self) -> usize {
        self.buffer_config.streaming_threshold()
    }

    /// Stream a large message directly to the socket, bypassing the ring buffer
    /// This provides maximum performance for large messages like PreBacktest
    pub async fn stream_large_message(
        &self,
        msg: &[u8],
        type_hash: u32,
        actor_id: u64,
    ) -> Result<()> {
        use crate::{current_timestamp, MessageType, StreamHeader};

        const CHUNK_SIZE: usize = STREAM_CHUNK_SIZE;

        // Acquire streaming mode atomically
        while self
            .streaming_active
            .compare_exchange(false, true, Ordering::AcqRel, Ordering::Acquire)
            .is_err()
        {
            tokio::task::yield_now().await;
        }

        // Ensure we release streaming mode on exit
        let _guard = StreamingGuard {
            flag: self.streaming_active.clone(),
        };

        // Generate unique stream ID
        let stream_id = current_timestamp();

        // Helper to serialize message with type and header
        fn serialize_stream_message(msg_type: MessageType, header: &StreamHeader) -> Vec<u8> {
            // Message format: [length:4][type:1][correlation_id:2][reserved:5][header:36]
            let inner_size = 8 + StreamHeader::SERIALIZED_SIZE;
            let mut message = Vec::with_capacity(4 + inner_size);

            // Length prefix (required by protocol)
            message.extend_from_slice(&(inner_size as u32).to_be_bytes());

            // Header
            message.push(msg_type as u8);
            message.extend_from_slice(&[0, 0]); // correlation_id (not used for streaming)
            message.extend_from_slice(&[0, 0, 0, 0, 0]); // reserved
            message.extend_from_slice(&header.to_bytes());
            message
        }

        // Send StreamStart header
        let start_header = StreamHeader {
            stream_id,
            total_size: msg.len() as u64,
            chunk_size: 0,
            chunk_index: 0,
            type_hash,
            actor_id,
        };

        let start_msg = serialize_stream_message(MessageType::StreamStart, &start_header);
        self.streaming_tx
            .send(StreamingCommand::WriteBytes(start_msg.into()))
            .map_err(|_| GossipError::Shutdown)?;

        // Stream chunks directly
        for (idx, chunk) in msg.chunks(CHUNK_SIZE).enumerate() {
            let data_header = StreamHeader {
                stream_id,
                total_size: msg.len() as u64,
                chunk_size: chunk.len() as u32,
                chunk_index: idx as u32,
                type_hash,
                actor_id,
            };

            // Create combined message with proper length prefix
            // Message format: [length:4][type:1][correlation_id:2][reserved:5][header:36][chunk_data:N]
            let inner_size = 8 + StreamHeader::SERIALIZED_SIZE + chunk.len();
            let mut chunk_msg = Vec::with_capacity(4 + inner_size);

            // Length prefix (includes header + chunk data)
            chunk_msg.extend_from_slice(&(inner_size as u32).to_be_bytes());

            // Header
            chunk_msg.push(MessageType::StreamData as u8);
            chunk_msg.extend_from_slice(&[0, 0]); // correlation_id
            chunk_msg.extend_from_slice(&[0, 0, 0, 0, 0]); // reserved
            chunk_msg.extend_from_slice(&data_header.to_bytes());

            // Chunk data
            chunk_msg.extend_from_slice(chunk);

            self.streaming_tx
                .send(StreamingCommand::WriteBytes(chunk_msg.into()))
                .map_err(|_| GossipError::Shutdown)?;

            // Yield periodically to prevent blocking
            if idx % 10 == 0 {
                self.streaming_tx
                    .send(StreamingCommand::Flush)
                    .map_err(|_| GossipError::Shutdown)?;
                tokio::task::yield_now().await;
            }
        }

        // Send StreamEnd
        let end_msg = serialize_stream_message(MessageType::StreamEnd, &start_header);
        self.streaming_tx
            .send(StreamingCommand::WriteBytes(end_msg.into()))
            .map_err(|_| GossipError::Shutdown)?;
        self.streaming_tx
            .send(StreamingCommand::Flush)
            .map_err(|_| GossipError::Shutdown)?;

        debug!(
            "âœ… STREAMING: Successfully streamed {} MB in {} chunks",
            msg.len() as f64 / 1_048_576.0,
            (msg.len() + CHUNK_SIZE - 1) / CHUNK_SIZE
        );

        Ok(())
    }

    /// Zero-copy vectored write for header + payload in single operation
    /// This eliminates copying payload data into frame buffer - optimal for streaming
    pub fn write_bytes_vectored(&self, header: bytes::Bytes, payload: bytes::Bytes) -> Result<()> {
        // Create vectored command that preserves both header and payload as separate Bytes
        let command = VectoredWriteCommand {
            header,
            payload,
        };

        // Try to send via streaming channel first for vectored operations
        match self
            .streaming_tx
            .send(StreamingCommand::VectoredWrite(command))
        {
            Ok(_) => Ok(()),
            Err(send_error) => {
                // Fallback: combine into single write if streaming channel is closed
                let cmd = send_error.0;
                if let StreamingCommand::VectoredWrite(vectored_cmd) = cmd {
                    let total_len = vectored_cmd.header.len() + vectored_cmd.payload.len();
                    let mut combined = bytes::BytesMut::with_capacity(total_len);
                    combined.extend_from_slice(&vectored_cmd.header);
                    combined.extend_from_slice(&vectored_cmd.payload);
                    self.write_bytes_nonblocking(combined.freeze())
                } else {
                    Err(GossipError::Shutdown)
                }
            }
        }
    }

    /// Send owned chunks without copying - optimal for streaming large messages
    pub fn write_owned_chunks(&self, chunks: Vec<bytes::Bytes>) -> Result<()> {
        if chunks.is_empty() {
            return Ok(());
        }

        // Send chunks as a batch via streaming channel for optimal vectored I/O
        let command = StreamingCommand::OwnedChunks(chunks);
        self.streaming_tx
            .send(command)
            .map_err(|_| GossipError::Shutdown)?;

        Ok(())
    }
}

/// Guard to ensure streaming_active is released on drop
struct StreamingGuard {
    flag: Arc<AtomicBool>,
}

impl Drop for StreamingGuard {
    fn drop(&mut self) {
        self.flag.store(false, Ordering::Release);
    }
}

impl Debug for LockFreeStreamHandle {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("LockFreeStreamHandle")
            .field("addr", &self.addr)
            .field("channel_id", &self.channel_id)
            .field("bytes_written", &self.bytes_written.load(Ordering::Relaxed))
            .field("sequence", &self.sequence_counter.load(Ordering::Relaxed))
            .finish()
    }
}

/// Message types for seamless batching with tell()
pub enum TellMessage<'a> {
    Single(&'a [u8]),
    Batch(Vec<&'a [u8]>),
}

impl<'a> TellMessage<'a> {
    /// Create a single message
    pub fn single(data: &'a [u8]) -> Self {
        Self::Single(data)
    }

    /// Create a batch message
    pub fn batch(messages: Vec<&'a [u8]>) -> Self {
        Self::Batch(messages)
    }

    /// Create from a slice - automatically detects single vs batch
    pub fn from_slice(messages: &'a [&'a [u8]]) -> Self {
        if messages.len() == 1 {
            Self::Single(messages[0])
        } else {
            Self::Batch(messages.to_vec())
        }
    }

    /// Send this message via the connection handle
    pub async fn send_via(self, handle: &ConnectionHandle) -> Result<()> {
        match self {
            TellMessage::Single(data) => handle.tell_raw(data).await,
            TellMessage::Batch(messages) => handle.tell_batch(&messages).await,
        }
    }
}

/// Implement From trait for automatic conversion
impl<'a> From<&'a [u8]> for TellMessage<'a> {
    fn from(data: &'a [u8]) -> Self {
        Self::Single(data)
    }
}

impl<'a> From<Vec<&'a [u8]>> for TellMessage<'a> {
    fn from(messages: Vec<&'a [u8]>) -> Self {
        if messages.len() == 1 {
            Self::Single(messages[0])
        } else {
            Self::Batch(messages)
        }
    }
}

impl<'a> From<&'a [&'a [u8]]> for TellMessage<'a> {
    fn from(messages: &'a [&'a [u8]]) -> Self {
        if messages.len() == 1 {
            Self::Single(messages[0])
        } else {
            Self::Batch(messages.to_vec())
        }
    }
}

impl<'a, const N: usize> From<&'a [u8; N]> for TellMessage<'a> {
    fn from(data: &'a [u8; N]) -> Self {
        Self::Single(data.as_slice())
    }
}

impl<'a> From<&'a Vec<u8>> for TellMessage<'a> {
    fn from(data: &'a Vec<u8>) -> Self {
        Self::Single(data.as_slice())
    }
}

/// Macro for ergonomic tell message creation
#[macro_export]
macro_rules! tell_msg {
    ($single:expr) => {
        TellMessage::single($single)
    };
    ($($msg:expr),+ $(,)?) => {
        TellMessage::batch(vec![$($msg),+])
    };
}

/// Connection pool for maintaining persistent TCP connections to peers
/// All connections are persistent - there is no checkout/checkin
/// Lock-free connection pool using atomic operations and lock-free data structures
pub struct ConnectionPool {
    /// PRIMARY: Mapping Peer ID -> LockFreeConnection
    /// This is the main storage - we identify connections by peer ID, not address
    connections_by_peer: dashmap::DashMap<crate::PeerId, Arc<LockFreeConnection>>,
    /// SECONDARY: Mapping SocketAddr -> Peer ID (for incoming connection identification)
    addr_to_peer_id: dashmap::DashMap<SocketAddr, crate::PeerId>,
    /// Configuration: Peer ID -> Expected SocketAddr (where to connect)
    pub peer_id_to_addr: dashmap::DashMap<crate::PeerId, SocketAddr>,
    /// DEPRECATED: Old address-based connections for migration
    connections: dashmap::DashMap<SocketAddr, Arc<LockFreeConnection>>,
    /// Shared correlation trackers by peer ID - ensures ask/response works across bidirectional connections
    correlation_trackers: dashmap::DashMap<crate::PeerId, Arc<CorrelationTracker>>,
    max_connections: usize,
    connection_timeout: Duration,
    /// Registry reference for handling incoming messages
    registry: Option<std::sync::Weak<GossipRegistry>>,
    /// Shared message buffer pool for zero-allocation processing
    message_buffer_pool: Arc<MessageBufferPool>,
    /// Connection counter for load balancing
    connection_counter: AtomicUsize,
}

/// Maximum number of pending responses (must be power of 2 for fast modulo)
const PENDING_RESPONSES_SIZE: usize = 1024;

/// Pending response slot
type PendingResponse = Option<tokio::sync::oneshot::Sender<Vec<u8>>>;

/// Shared state for correlation tracking
pub(crate) struct CorrelationTracker {
    /// Next correlation ID to use
    next_id: AtomicU16,
    /// Fixed-size array of pending responses
    pending: [parking_lot::Mutex<PendingResponse>; PENDING_RESPONSES_SIZE],
}

impl std::fmt::Debug for CorrelationTracker {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("CorrelationTracker")
            .field("next_id", &self.next_id.load(Ordering::Relaxed))
            .finish()
    }
}

impl CorrelationTracker {
    fn new() -> Arc<Self> {
        // Create array of None values
        let pending = std::array::from_fn(|_| parking_lot::Mutex::new(None));
        Arc::new(Self {
            next_id: AtomicU16::new(1),
            pending,
        })
    }

    /// Allocate a correlation ID and store the response sender
    fn allocate(&self, sender: tokio::sync::oneshot::Sender<Vec<u8>>) -> u16 {
        loop {
            let id = self.next_id.fetch_add(1, Ordering::Relaxed);
            if id == 0 {
                continue; // Skip 0 as it's reserved
            }

            let slot = (id as usize) % PENDING_RESPONSES_SIZE;
            let mut pending = self.pending[slot].lock();

            // If slot is empty, use it
            if pending.is_none() {
                *pending = Some(sender);
                debug!(
                    "CorrelationTracker: Allocated correlation_id {} in slot {}",
                    id, slot
                );
                return id;
            }

            // Slot is occupied, try next ID
            debug!("CorrelationTracker: Slot {} occupied, trying next ID", slot);
        }
    }

    /// Check if a correlation ID has a pending request
    fn has_pending(&self, correlation_id: u16) -> bool {
        let slot = (correlation_id as usize) % PENDING_RESPONSES_SIZE;
        let pending = self.pending[slot].lock();
        pending.is_some()
    }

    /// Complete a pending request with a response
    fn complete(&self, correlation_id: u16, response: Vec<u8>) {
        let slot = (correlation_id as usize) % PENDING_RESPONSES_SIZE;
        let mut pending = self.pending[slot].lock();

        if let Some(sender) = pending.take() {
            match sender.send(response) {
                Ok(_) => {}
                Err(_) => {}
            }
        }
    }
}

/// Handle to send messages through a persistent connection - LOCK-FREE
#[derive(Clone)]
pub struct ConnectionHandle {
    pub addr: SocketAddr,
    // Direct lock-free stream handle - NO MUTEX!
    stream_handle: Arc<LockFreeStreamHandle>,
    // Correlation tracker for ask/response
    correlation: Arc<CorrelationTracker>,
}

impl std::fmt::Debug for ConnectionHandle {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("ConnectionHandle")
            .field("addr", &self.addr)
            .field("stream_handle", &self.stream_handle)
            .finish()
    }
}

/// Delegated reply sender for asynchronous response handling
/// Allows passing around the ability to reply to a request without blocking the original caller
pub struct DelegatedReplySender {
    sender: tokio::sync::oneshot::Sender<Vec<u8>>,
    receiver: tokio::sync::oneshot::Receiver<Vec<u8>>,
    request_len: usize,
    timeout: Option<Duration>,
    created_at: std::time::Instant,
}

impl DelegatedReplySender {
    /// Create a new delegated reply sender
    pub fn new(
        sender: tokio::sync::oneshot::Sender<Vec<u8>>,
        receiver: tokio::sync::oneshot::Receiver<Vec<u8>>,
        request_len: usize,
    ) -> Self {
        Self {
            sender,
            receiver,
            request_len,
            timeout: None,
            created_at: std::time::Instant::now(),
        }
    }

    /// Create a new delegated reply sender with timeout
    pub fn new_with_timeout(
        sender: tokio::sync::oneshot::Sender<Vec<u8>>,
        receiver: tokio::sync::oneshot::Receiver<Vec<u8>>,
        request_len: usize,
        timeout: Duration,
    ) -> Self {
        Self {
            sender,
            receiver,
            request_len,
            timeout: Some(timeout),
            created_at: std::time::Instant::now(),
        }
    }

    /// Send a reply using this delegated sender
    /// This can be called from anywhere in the code to complete the request-response cycle
    pub fn reply(self, response: Vec<u8>) -> Result<()> {
        match self.sender.send(response) {
            Ok(()) => Ok(()),
            Err(_) => Err(GossipError::Network(std::io::Error::new(
                std::io::ErrorKind::BrokenPipe,
                "Reply receiver was dropped",
            ))),
        }
    }

    /// Send a reply with error
    pub fn reply_error(self, error: &str) -> Result<()> {
        let error_response = format!("ERROR:{}", error).into_bytes();
        self.reply(error_response)
    }

    /// Wait for the reply with optional timeout
    pub async fn wait_for_reply(self) -> Result<Vec<u8>> {
        if let Some(timeout) = self.timeout {
            match tokio::time::timeout(timeout, self.receiver).await {
                Ok(Ok(response)) => Ok(response),
                Ok(Err(_)) => Err(GossipError::Network(std::io::Error::new(
                    std::io::ErrorKind::BrokenPipe,
                    "Reply sender was dropped",
                ))),
                Err(_) => Err(GossipError::Timeout),
            }
        } else {
            match self.receiver.await {
                Ok(response) => Ok(response),
                Err(_) => Err(GossipError::Network(std::io::Error::new(
                    std::io::ErrorKind::BrokenPipe,
                    "Reply sender was dropped",
                ))),
            }
        }
    }

    /// Wait for the reply with a custom timeout
    pub async fn wait_for_reply_with_timeout(self, timeout: Duration) -> Result<Vec<u8>> {
        match tokio::time::timeout(timeout, self.receiver).await {
            Ok(Ok(response)) => Ok(response),
            Ok(Err(_)) => Err(GossipError::Network(std::io::Error::new(
                std::io::ErrorKind::BrokenPipe,
                "Reply sender was dropped",
            ))),
            Err(_) => Err(GossipError::Timeout),
        }
    }

    /// Get the original request length (useful for creating mock responses)
    pub fn request_len(&self) -> usize {
        self.request_len
    }

    /// Get the elapsed time since the request was made
    pub fn elapsed(&self) -> Duration {
        self.created_at.elapsed()
    }

    /// Check if this reply sender has timed out
    pub fn is_timed_out(&self) -> bool {
        if let Some(timeout) = self.timeout {
            self.created_at.elapsed() > timeout
        } else {
            false
        }
    }

    /// Create a mock reply for testing (simulates the original ask() behavior)
    pub fn create_mock_reply(&self) -> Vec<u8> {
        format!("RESPONSE:{}", self.request_len).into_bytes()
    }
}

impl std::fmt::Debug for DelegatedReplySender {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        f.debug_struct("DelegatedReplySender")
            .field("request_len", &self.request_len)
            .field("timeout", &self.timeout)
            .field("elapsed", &self.elapsed())
            .field("is_timed_out", &self.is_timed_out())
            .finish()
    }
}

impl ConnectionHandle {
    /// Send pre-serialized data through this connection - LOCK-FREE
    pub async fn send_data(&self, data: Vec<u8>) -> Result<()> {
        // Use lock-free ring buffer - NO MUTEX!
        // Convert Vec<u8> to Bytes for zero-copy
        self.stream_handle
            .write_bytes_nonblocking(bytes::Bytes::from(data))
    }

    /// Send raw bytes without any framing - used by ReplyTo
    pub fn send_raw_bytes(&self, data: &[u8]) -> Result<()> {
        // Must copy here since we don't own the data
        self.stream_handle
            .write_bytes_nonblocking(bytes::Bytes::copy_from_slice(data))
    }

    /// Send bytes without copying - TRUE ZERO-COPY
    pub fn send_bytes_zero_copy(&self, data: bytes::Bytes) -> Result<()> {
        // eprintln!("[CONNECTION] Sending {} bytes on connection to {}", data.len(), self.stream_handle.addr);
        self.stream_handle.write_bytes_nonblocking(data)?;
        // CRITICAL: Flush immediately to ensure message is sent
        self.stream_handle.flush_immediately()
    }

    /// Stream a large message directly - MAXIMUM PERFORMANCE
    pub async fn stream_large_message(
        &self,
        msg: &[u8],
        type_hash: u32,
        actor_id: u64,
    ) -> Result<()> {
        self.stream_handle
            .stream_large_message(msg, type_hash, actor_id)
            .await
    }

    /// Get the streaming threshold for this connection
    ///
    /// Messages larger than this threshold should be sent via streaming
    /// rather than through the ring buffer to prevent message loss.
    pub fn streaming_threshold(&self) -> usize {
        self.stream_handle.streaming_threshold()
    }

    /// Raw tell() - LOCK-FREE write (used internally)
    pub async fn tell_raw(&self, data: &[u8]) -> Result<()> {
        // Create message with length header using BytesMut for efficiency
        let mut message = bytes::BytesMut::with_capacity(4 + data.len());
        message.extend_from_slice(&(data.len() as u32).to_be_bytes());
        message.extend_from_slice(data);

        // Use lock-free ring buffer - NO MUTEX!
        self.stream_handle
            .write_bytes_nonblocking(message.freeze())?;

        // CRITICAL: Flush immediately for low-latency tell operations
        self.stream_handle.flush_immediately()
    }

    /// Send a pre-formatted binary message (already has length prefix)
    pub async fn send_binary_message(&self, message: &[u8]) -> Result<()> {
        // Message already has length prefix, send as-is
        self.stream_handle
            .write_bytes_nonblocking(bytes::Bytes::copy_from_slice(message))
    }

    /// Smart tell() - accepts TellMessage with automatic batch detection
    pub async fn tell<'a, T: Into<TellMessage<'a>>>(&self, message: T) -> Result<()> {
        let tell_message = message.into();
        tell_message.send_via(self).await
    }

    /// Legacy tell() for backward compatibility
    pub async fn tell_single(&self, data: &[u8]) -> Result<()> {
        self.tell_raw(data).await
    }

    /// Smart tell() - automatically uses batching for Vec<T>
    pub async fn tell_smart<T: AsRef<[u8]>>(&self, payload: &[T]) -> Result<()> {
        if payload.len() == 1 {
            // Single message - use regular tell
            self.tell(payload[0].as_ref()).await
        } else {
            // Multiple messages - use batch
            let batch: Vec<&[u8]> = payload.iter().map(|item| item.as_ref()).collect();
            self.tell_batch(&batch).await
        }
    }

    /// Tell with automatic batching detection
    pub async fn tell_auto(&self, data: &[u8]) -> Result<()> {
        // Single message path
        self.tell(data).await
    }

    /// Tell multiple messages with a single call
    pub async fn tell_many<T: AsRef<[u8]>>(&self, messages: &[T]) -> Result<()> {
        if messages.is_empty() {
            return Ok(());
        }

        if messages.len() == 1 {
            // Single message optimization
            self.tell(messages[0].as_ref()).await
        } else {
            // Batch multiple messages
            let batch: Vec<&[u8]> = messages.iter().map(|msg| msg.as_ref()).collect();
            self.tell_batch(&batch).await
        }
    }

    /// Send a TellMessage (single or batch) - same as tell() but explicit
    pub async fn send_tell_message(&self, message: TellMessage<'_>) -> Result<()> {
        message.send_via(self).await
    }

    /// Universal send() - detects single vs multiple messages automatically
    pub async fn send_messages(&self, messages: &[&[u8]]) -> Result<()> {
        if messages.is_empty() {
            return Ok(());
        }

        if messages.len() == 1 {
            self.tell_raw(messages[0]).await
        } else {
            self.tell_batch(messages).await
        }
    }

    /// Batch tell() for multiple messages - LOCK-FREE
    pub async fn tell_batch(&self, messages: &[&[u8]]) -> Result<()> {
        // OPTIMIZATION: Pre-calculate total size and write in one go
        let total_size: usize = messages.iter().map(|m| 4 + m.len()).sum();
        let mut batch_buffer = bytes::BytesMut::with_capacity(total_size);

        for msg in messages {
            batch_buffer.extend_from_slice(&(msg.len() as u32).to_be_bytes());
            batch_buffer.extend_from_slice(msg);
        }

        // Use lock-free ring buffer - NO MUTEX!
        self.stream_handle
            .write_bytes_nonblocking(batch_buffer.freeze())?;

        // CRITICAL: Flush immediately for low-latency operations
        self.stream_handle.flush_immediately()
    }

    /// Direct access to try_send for maximum performance testing
    pub fn try_send_direct(&self, _data: &[u8]) -> Result<()> {
        // Direct TCP doesn't support try_send - would need try_lock
        Err(GossipError::Network(std::io::Error::new(
            std::io::ErrorKind::WouldBlock,
            "use tell() for direct TCP writes",
        )))
    }

    /// Send raw bytes through existing connection (zero-copy where possible)
    pub async fn send_raw(&self, data: &[u8]) -> Result<()> {
        // Direct TCP write
        self.tell_raw(data).await
    }

    /// Ask method for request-response (Note: This is a simplified implementation)
    /// For full request-response, you would need a proper protocol with correlation IDs
    pub async fn ask(&self, request: &[u8]) -> Result<Vec<u8>> {
        // Use default timeout of 30 seconds
        self.ask_with_timeout(request, Duration::from_secs(30))
            .await
    }

    /// Ask method with custom timeout for request-response
    pub async fn ask_with_timeout(&self, request: &[u8], timeout: Duration) -> Result<Vec<u8>> {
        // Create oneshot channel for response
        let (tx, rx) = tokio::sync::oneshot::channel();

        // Allocate correlation ID
        let correlation_id = self.correlation.allocate(tx);

        // Create ask message with length prefix + 8-byte header + payload
        let total_size = 8 + request.len();
        let mut message = bytes::BytesMut::with_capacity(4 + total_size);

        // Length prefix (4 bytes)
        message.extend_from_slice(&(total_size as u32).to_be_bytes());

        // Header: [type:1][correlation_id:2][reserved:5]
        let ask_type = crate::MessageType::Ask as u8;
        message.put_u8(ask_type);
        message.extend_from_slice(&correlation_id.to_be_bytes());
        message.extend_from_slice(&[0u8; 5]); // Reserved bytes
        message.extend_from_slice(request);

        // Send the message
        self.stream_handle
            .write_bytes_nonblocking(message.freeze())?;

        // CRITICAL: Flush immediately for ask messages to minimize latency
        self.stream_handle.flush_immediately()?;

        // Wait for response with custom timeout
        let result = match tokio::time::timeout(timeout, rx).await {
            Ok(Ok(response)) => Ok(response),
            Ok(Err(_)) => Err(crate::GossipError::Network(std::io::Error::new(
                std::io::ErrorKind::Other,
                "Response channel closed",
            ))),
            Err(_) => Err(crate::GossipError::Timeout),
        };

        result
    }

    /// Ask method that returns a ReplyTo handle for delegated replies
    pub async fn ask_with_reply_to(&self, request: &[u8]) -> Result<crate::ReplyTo> {
        // Create oneshot channel for response (we won't use it for ReplyTo)
        let (tx, _rx) = tokio::sync::oneshot::channel();

        // Allocate correlation ID
        let correlation_id = self.correlation.allocate(tx);

        // Create ask message with length prefix + 8-byte header + payload
        let total_size = 8 + request.len();
        let mut message = bytes::BytesMut::with_capacity(4 + total_size);

        // Length prefix (4 bytes)
        message.extend_from_slice(&(total_size as u32).to_be_bytes());

        // Header: [type:1][correlation_id:2][reserved:5]
        message.put_u8(crate::MessageType::Ask as u8);
        message.extend_from_slice(&correlation_id.to_be_bytes());
        message.extend_from_slice(&[0u8; 5]); // Reserved bytes
        message.extend_from_slice(request);

        // Send the message
        self.stream_handle
            .write_bytes_nonblocking(message.freeze())?;

        // CRITICAL: Flush immediately for ask messages to minimize latency
        self.stream_handle.flush_immediately()?;

        // Return ReplyTo handle
        Ok(crate::ReplyTo {
            correlation_id,
            connection: Arc::new(self.clone()),
        })
    }

    /// Ask method with delegated reply sender for asynchronous response handling
    /// Returns a DelegatedReplySender that can be passed around to handle the response elsewhere
    pub async fn ask_with_reply_sender(&self, request: &[u8]) -> Result<DelegatedReplySender> {
        // Create a oneshot channel for the response
        let (reply_sender, reply_receiver) = tokio::sync::oneshot::channel();

        // Send the request (in a real implementation, this would include correlation ID)
        self.tell(request).await?;

        // Return the delegated reply sender
        Ok(DelegatedReplySender::new(
            reply_sender,
            reply_receiver,
            request.len(),
        ))
    }

    /// Ask method with timeout and delegated reply
    pub async fn ask_with_timeout_and_reply(
        &self,
        request: &[u8],
        timeout: Duration,
    ) -> Result<DelegatedReplySender> {
        // Create a oneshot channel for the response
        let (reply_sender, reply_receiver) = tokio::sync::oneshot::channel();

        // Send the request
        self.tell(request).await?;

        // Return the delegated reply sender with timeout
        Ok(DelegatedReplySender::new_with_timeout(
            reply_sender,
            reply_receiver,
            request.len(),
            timeout,
        ))
    }

    /// Batch ask method for multiple requests in a single network round-trip
    /// Returns a vector of response futures that can be awaited independently
    pub async fn ask_batch(
        &self,
        requests: &[&[u8]],
    ) -> Result<Vec<tokio::sync::oneshot::Receiver<Vec<u8>>>> {
        if requests.is_empty() {
            return Ok(Vec::new());
        }

        let mut receivers = Vec::with_capacity(requests.len());
        let mut batch_message = Vec::new();

        // Process each request
        for request in requests {
            // Create oneshot channel for this response
            let (tx, rx) = tokio::sync::oneshot::channel();
            receivers.push(rx);

            // Allocate correlation ID
            let correlation_id = self.correlation.allocate(tx);

            // Build ask message: [type:1][correlation_id:2][reserved:5] + payload
            let total_size = 8 + request.len();

            // Length prefix (4 bytes)
            batch_message.extend_from_slice(&(total_size as u32).to_be_bytes());

            // Header: [type:1][correlation_id:2][reserved:5]
            batch_message.push(crate::MessageType::Ask as u8);
            batch_message.extend_from_slice(&correlation_id.to_be_bytes());
            batch_message.extend_from_slice(&[0u8; 5]); // Reserved bytes
            batch_message.extend_from_slice(request);
        }

        // Send all messages in one write
        self.stream_handle
            .write_bytes_nonblocking(bytes::Bytes::from(batch_message))?;

        // CRITICAL: Flush immediately for ask messages to minimize latency
        self.stream_handle.flush_immediately()?;

        Ok(receivers)
    }

    /// Batch ask with timeout - returns Vec<Result<Vec<u8>>> with individual timeout handling
    pub async fn ask_batch_with_timeout(
        &self,
        requests: &[&[u8]],
        timeout: Duration,
    ) -> Result<Vec<Result<Vec<u8>>>> {
        let receivers = self.ask_batch(requests).await?;

        // Create futures for all responses with timeout
        let mut response_futures = Vec::with_capacity(receivers.len());

        for receiver in receivers {
            let timeout_future = async move {
                match tokio::time::timeout(timeout, receiver).await {
                    Ok(Ok(response)) => Ok(response),
                    Ok(Err(_)) => Err(crate::GossipError::Network(std::io::Error::new(
                        std::io::ErrorKind::Other,
                        "Response channel closed",
                    ))),
                    Err(_) => Err(crate::GossipError::Timeout),
                }
            };
            response_futures.push(timeout_future);
        }

        // Wait for all responses concurrently
        let results = futures::future::join_all(response_futures).await;
        Ok(results)
    }

    /// High-performance batch ask with pre-allocated buffers
    /// This version minimizes allocations for maximum throughput
    pub async fn ask_batch_optimized(
        &self,
        requests: &[&[u8]],
        response_buffer: &mut Vec<tokio::sync::oneshot::Receiver<Vec<u8>>>,
    ) -> Result<()> {
        response_buffer.clear();
        response_buffer.reserve(requests.len());

        // Pre-calculate total message size
        let total_size: usize = requests
            .iter()
            .map(|req| 4 + 8 + req.len()) // length prefix + header + payload
            .sum();

        let mut batch_message = bytes::BytesMut::with_capacity(total_size);

        // Build all messages
        for request in requests {
            // Create oneshot channel for this response
            let (tx, rx) = tokio::sync::oneshot::channel();
            response_buffer.push(rx);

            // Allocate correlation ID
            let correlation_id = self.correlation.allocate(tx);

            // Build ask message
            let msg_size = 8 + request.len();
            batch_message.extend_from_slice(&(msg_size as u32).to_be_bytes());
            batch_message.put_u8(crate::MessageType::Ask as u8);
            batch_message.extend_from_slice(&correlation_id.to_be_bytes());
            batch_message.extend_from_slice(&[0u8; 5]);
            batch_message.extend_from_slice(request);
        }

        // Single write for all messages
        self.stream_handle
            .write_bytes_nonblocking(batch_message.freeze())?;

        // CRITICAL: Flush immediately for ask messages to minimize latency
        self.stream_handle.flush_immediately()?;

        Ok(())
    }

    /// High-performance streaming API - send structured data with custom framing - LOCK-FREE
    pub async fn stream_send<T>(&self, data: &T) -> Result<()>
    where
        T: for<'a> rkyv::Serialize<
            rkyv::rancor::Strategy<
                rkyv::ser::Serializer<
                    rkyv::util::AlignedVec,
                    rkyv::ser::allocator::ArenaHandle<'a>,
                    rkyv::ser::sharing::Share,
                >,
                rkyv::rancor::Error,
            >,
        >,
    {
        // Serialize the data using rkyv for maximum performance
        let payload = rkyv::to_bytes::<rkyv::rancor::Error>(data)
            .map_err(|e| crate::GossipError::Serialization(e))?;

        // Create stream frame: [frame_type, channel_id, flags, seq_id[2], payload_len[4]]
        let frame_header = StreamFrameHeader {
            frame_type: StreamFrameType::Data as u8,
            channel_id: ChannelId::TellAsk as u8,
            flags: 0,
            sequence_id: 0, // TODO: Add sequence tracking for ordering
            payload_len: payload.len() as u32,
        };

        let header_bytes = rkyv::to_bytes::<rkyv::rancor::Error>(&frame_header)
            .map_err(|e| crate::GossipError::Serialization(e))?;

        // Combine header and payload for single write
        let mut combined = bytes::BytesMut::with_capacity(header_bytes.len() + payload.len());
        combined.extend_from_slice(&header_bytes);
        combined.extend_from_slice(&payload);

        // Use lock-free ring buffer - NO MUTEX!
        self.stream_handle
            .write_bytes_nonblocking(combined.freeze())
    }

    /// High-performance streaming API - send batch of structured data - LOCK-FREE
    pub async fn stream_send_batch<T>(&self, batch: &[T]) -> Result<()>
    where
        T: for<'a> rkyv::Serialize<
            rkyv::rancor::Strategy<
                rkyv::ser::Serializer<
                    rkyv::util::AlignedVec,
                    rkyv::ser::allocator::ArenaHandle<'a>,
                    rkyv::ser::sharing::Share,
                >,
                rkyv::rancor::Error,
            >,
        >,
    {
        if batch.is_empty() {
            return Ok(());
        }

        // Pre-allocate buffer for entire batch
        let mut total_payload = Vec::new();

        for item in batch {
            let payload = rkyv::to_bytes::<rkyv::rancor::Error>(item)
                .map_err(|e| crate::GossipError::Serialization(e))?;

            let frame_header = StreamFrameHeader {
                frame_type: StreamFrameType::Data as u8,
                channel_id: ChannelId::TellAsk as u8,
                flags: if item as *const _ == batch.last().unwrap() as *const _ {
                    0
                } else {
                    StreamFrameFlags::More as u8
                },
                sequence_id: 0, // TODO: Add sequence tracking
                payload_len: payload.len() as u32,
            };

            let header_bytes = rkyv::to_bytes::<rkyv::rancor::Error>(&frame_header)
                .map_err(|e| crate::GossipError::Serialization(e))?;
            total_payload.extend_from_slice(&header_bytes);
            total_payload.extend_from_slice(&payload);
        }

        // Use lock-free ring buffer for entire batch - NO MUTEX!
        self.stream_handle
            .write_bytes_nonblocking(bytes::Bytes::from(total_payload))
    }

    /// Get truly lock-free streaming handle - direct access to the internal handle
    pub fn get_lock_free_stream(&self) -> &Arc<LockFreeStreamHandle> {
        &self.stream_handle
    }

    /// Zero-copy vectored write for header + payload in single syscall
    /// This eliminates the need to copy payload data into frame buffer
    pub fn write_bytes_vectored(&self, header: bytes::Bytes, payload: bytes::Bytes) -> Result<()> {
        self.stream_handle.write_bytes_vectored(header, payload)
    }

    /// Send owned chunks without copying - optimal for streaming large messages
    pub fn write_owned_chunks(&self, chunks: Vec<bytes::Bytes>) -> Result<()> {
        self.stream_handle.write_owned_chunks(chunks)
    }
}

impl ConnectionPool {
    pub fn new(max_connections: usize, connection_timeout: Duration) -> Self {
        const POOL_SIZE: usize = 256;
        const BUFFER_SIZE: usize = TCP_BUFFER_SIZE / 128; // Smaller pool buffers (8KB default)

        let pool = Self {
            connections_by_peer: dashmap::DashMap::new(),
            addr_to_peer_id: dashmap::DashMap::new(),
            peer_id_to_addr: dashmap::DashMap::new(),
            connections: dashmap::DashMap::new(), // DEPRECATED
            correlation_trackers: dashmap::DashMap::new(),
            max_connections,
            connection_timeout,
            registry: None,
            message_buffer_pool: Arc::new(MessageBufferPool::new(POOL_SIZE, BUFFER_SIZE)),
            connection_counter: AtomicUsize::new(0),
        };

        // Log the pool's address for debugging
        debug!(
            "CONNECTION POOL: Created new pool at {:p}",
            &pool as *const _
        );
        pool
    }

    /// Set the registry reference for handling incoming messages
    pub fn set_registry(&mut self, registry: std::sync::Arc<GossipRegistry>) {
        self.registry = Some(std::sync::Arc::downgrade(&registry));
    }

    /// Store or update the address for a node
    /// Only updates if no address is already configured for this node
    pub fn update_node_address(&self, node_id: &str, addr: SocketAddr) {
        let peer_id = crate::PeerId::new(node_id);

        // Check if we already have a configured address for this node
        if let Some(existing_addr_entry) = self.peer_id_to_addr.get(&peer_id) {
            let existing_addr = *existing_addr_entry.value();
            debug!("CONNECTION POOL: Node {} already has configured address {}, not updating to ephemeral port {}", 
                   node_id, existing_addr, addr);
            return;
        }

        // Only update if no address is configured
        self.peer_id_to_addr.insert(peer_id.clone(), addr);
        self.addr_to_peer_id.insert(addr, peer_id);
        debug!(
            "CONNECTION POOL: Set initial address for node {} to {}",
            node_id, addr
        );
    }

    /// Get a connection by node ID
    pub fn get_connection_by_node_id(&self, node_id: &str) -> Option<Arc<LockFreeConnection>> {
        // PRIMARY: Look up connection directly by node ID
        let peer_id = crate::PeerId::new(node_id);
        if let Some(conn_entry) = self.connections_by_peer.get(&peer_id) {
            let conn = conn_entry.value().clone();
            if conn.is_connected() {
                debug!("CONNECTION POOL: Found connection for node '{}'", node_id);
                Some(conn)
            } else {
                warn!(
                    "CONNECTION POOL: Connection for node '{}' is disconnected",
                    node_id
                );
                None
            }
        } else {
            warn!(
                "CONNECTION POOL: No connection found for node '{}'",
                node_id
            );
            // Debug: show what nodes we do have connections for
            let connected_nodes: Vec<String> = self
                .connections_by_peer
                .iter()
                .map(|entry| entry.key().as_str().to_string())
                .collect();
            warn!(
                "CONNECTION POOL: Available node connections: {:?}",
                connected_nodes
            );
            None
        }
    }

    /// Get or create a correlation tracker for a peer
    pub(crate) fn get_or_create_correlation_tracker(
        &self,
        peer_id: &crate::PeerId,
    ) -> Arc<CorrelationTracker> {
        let tracker = self
            .correlation_trackers
            .entry(peer_id.clone())
            .or_insert_with(|| {
                debug!(
                    "CONNECTION POOL: Creating new correlation tracker for peer {}",
                    peer_id
                );
                CorrelationTracker::new()
            })
            .clone();
        debug!(
            "CONNECTION POOL: Got correlation tracker for peer {} (total trackers: {})",
            peer_id,
            self.correlation_trackers.len()
        );
        tracker
    }

    /// Add a connection indexed by node ID
    pub fn add_connection_by_node_id(
        &self,
        node_id: String,
        addr: SocketAddr,
        mut connection: Arc<LockFreeConnection>,
    ) -> bool {
        // Convert to PeerId
        let peer_id = crate::PeerId::new(&node_id);

        // Only set correlation tracker if the connection doesn't already have one
        if connection.correlation.is_none() {
            // Get or create shared correlation tracker for this peer
            let correlation_tracker = self.get_or_create_correlation_tracker(&peer_id);

            // Set the correlation tracker on the connection
            // We need to make the connection mutable
            if let Some(conn_mut) = Arc::get_mut(&mut connection) {
                conn_mut.correlation = Some(correlation_tracker);
            } else {
                warn!(
                    "CONNECTION POOL: Cannot set correlation tracker - Arc has multiple references"
                );
            }
        } else {
            // Connection already has a correlation tracker - ensure it's registered
            if let Some(ref correlation) = connection.correlation {
                self.correlation_trackers
                    .insert(peer_id.clone(), correlation.clone());
                debug!(
                    "CONNECTION POOL: Registered existing correlation tracker for node '{}'",
                    node_id
                );
            }
        }

        // Update the address mappings
        self.addr_to_peer_id.insert(addr, peer_id.clone());

        // PRIMARY: Store the connection by peer ID
        self.connections_by_peer.insert(peer_id, connection.clone());

        // DEPRECATED: Also store by address for backward compatibility
        self.connections.insert(addr, connection);

        self.connection_counter.fetch_add(1, Ordering::AcqRel);

        debug!(
            "CONNECTION POOL: Added connection for node '{}' (address: {})",
            node_id, addr
        );
        true
    }

    /// Send data to a node by ID
    pub fn send_to_node_id(&self, node_id: &str, data: &[u8]) -> Result<()> {
        debug!(
            "CONNECTION POOL: send_to_node_id called for node '{}', pool has {} node connections",
            node_id,
            self.connections_by_peer.len()
        );
        if let Some(connection) = self.get_connection_by_node_id(node_id) {
            if let Some(ref stream_handle) = connection.stream_handle {
                debug!(
                    "CONNECTION POOL: Sending {} bytes to node '{}'",
                    data.len(),
                    node_id
                );
                return stream_handle.write_bytes_nonblocking(bytes::Bytes::copy_from_slice(data));
            } else {
                warn!(node_id = %node_id, "Connection found but no stream handle");
            }
        } else {
            warn!(node_id = %node_id, "No connection found for node");
        }
        Err(crate::GossipError::Network(std::io::Error::new(
            std::io::ErrorKind::NotFound,
            format!("Connection not found for node {}", node_id),
        )))
    }

    /// Send bytes to a node by its ID (zero-copy version)
    pub fn send_bytes_to_node_id(&self, node_id: &str, data: bytes::Bytes) -> Result<()> {
        debug!("CONNECTION POOL: send_bytes_to_node_id called for node '{}', pool has {} node connections", 
              node_id, self.connections_by_peer.len());
        if let Some(connection) = self.get_connection_by_node_id(node_id) {
            if let Some(ref stream_handle) = connection.stream_handle {
                debug!(
                    "CONNECTION POOL: Sending {} bytes to node '{}'",
                    data.len(),
                    node_id
                );
                return stream_handle.write_bytes_nonblocking(data);
            } else {
                warn!(node_id = %node_id, "Connection found but no stream handle");
            }
        } else {
            warn!(node_id = %node_id, "No connection found for node");
        }
        Err(crate::GossipError::Network(std::io::Error::new(
            std::io::ErrorKind::NotFound,
            format!("Connection not found for node {}", node_id),
        )))
    }

    /// Get or create a lock-free connection - NO MUTEX NEEDED
    pub fn get_lock_free_connection(&self, addr: SocketAddr) -> Option<Arc<LockFreeConnection>> {
        self.connections
            .get(&addr)
            .map(|entry| entry.value().clone())
    }

    /// Add a new lock-free connection - completely lock-free operation
    pub fn add_lock_free_connection(
        &self,
        addr: SocketAddr,
        tcp_stream: TcpStream,
    ) -> Result<Arc<LockFreeConnection>> {
        let connection_count = self.connection_counter.fetch_add(1, Ordering::AcqRel);

        if connection_count >= self.max_connections {
            self.connection_counter.fetch_sub(1, Ordering::AcqRel);
            return Err(crate::GossipError::Network(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("Max connections ({}) reached", self.max_connections),
            )));
        }

        // Split the stream for reading and writing
        let (reader, writer) = tcp_stream.into_split();

        // Create lock-free streaming handle with exclusive socket ownership
        let stream_handle = Arc::new(LockFreeStreamHandle::new(
            writer, // Pass writer half
            addr,
            ChannelId::Global,
            BufferConfig::default(),
        ));

        let mut connection = LockFreeConnection::new(addr);
        connection.stream_handle = Some(stream_handle);
        connection.set_state(ConnectionState::Connected);
        connection.update_last_used();

        let connection_arc = Arc::new(connection);

        // Spawn reader task for this connection
        // This reader needs to process incoming messages on outgoing connections
        let reader_connection = connection_arc.clone();
        let registry_weak = self.registry.clone();
        tokio::spawn(async move {
            info!(peer = %addr, "Starting reader task for outgoing connection");
            handle_persistent_connection_reader(reader, None, addr, registry_weak).await;
            reader_connection.set_state(ConnectionState::Disconnected);
            info!(peer = %addr, "Reader task for outgoing connection ended");
        });

        // Insert into lock-free hash map
        self.connections.insert(addr, connection_arc.clone());
        debug!(
            "CONNECTION POOL: Added lock-free connection to {} - pool now has {} connections",
            addr,
            self.connections.len()
        );

        Ok(connection_arc)
    }

    /// Send data through lock-free connection - NO BLOCKING
    pub fn send_lock_free(&self, addr: SocketAddr, data: &[u8]) -> Result<()> {
        if let Some(connection) = self.get_lock_free_connection(addr) {
            if let Some(ref stream_handle) = connection.stream_handle {
                return stream_handle.write_bytes_nonblocking(bytes::Bytes::copy_from_slice(data));
            } else {
                warn!(addr = %addr, "Connection found but no stream handle");
            }
        } else {
            warn!(addr = %addr, "No connection found for address");
            warn!(
                "Available connections: {:?}",
                self.connections
                    .iter()
                    .map(|e| e.key().clone())
                    .collect::<Vec<_>>()
            );
        }
        Err(crate::GossipError::Network(std::io::Error::new(
            std::io::ErrorKind::NotFound,
            "Connection not found",
        )))
    }

    /// Try to send data through any available connection for a node
    /// This handles cases where we might have multiple connections (incoming/outgoing)
    pub fn send_to_node(
        &self,
        node_addr: SocketAddr,
        data: &[u8],
        _registry: &GossipRegistry,
    ) -> Result<()> {
        // First try direct lookup
        if let Ok(()) = self.send_lock_free(node_addr, data) {
            return Ok(());
        }

        // If that fails, look for any connection that could reach this node
        // This could be enhanced with a node ID -> connections mapping
        debug!(node_addr = %node_addr, "Direct send failed, looking for alternative connections");

        // For now, we'll rely on the caller to handle fallback strategies
        Err(crate::GossipError::Network(std::io::Error::new(
            std::io::ErrorKind::NotFound,
            format!("No connection found for node {}", node_addr),
        )))
    }

    /// Remove a connection from the pool - lock-free operation
    pub fn remove_connection(&self, addr: SocketAddr) -> Option<Arc<LockFreeConnection>> {
        // First remove from address-based map
        if let Some((_, connection)) = self.connections.remove(&addr) {
            debug!(
                "CONNECTION POOL: Removed connection to {} - pool now has {} connections",
                addr,
                self.connections.len()
            );

            // Also remove from node ID mapping
            if let Some(node_id_entry) = self.addr_to_peer_id.remove(&addr) {
                let (_, node_id) = node_id_entry;
                if let Some((_, _)) = self.connections_by_peer.remove(&node_id) {
                    debug!(
                        "CONNECTION POOL: Also removed connection by node ID '{}'",
                        node_id
                    );
                }
            }

            self.connection_counter.fetch_sub(1, Ordering::AcqRel);
            Some(connection)
        } else {
            None
        }
    }

    /// Get connection count - lock-free operation
    pub fn connection_count(&self) -> usize {
        // For the migration period, just count the legacy connections since that's what
        // existing tests like test_connection_pool_full expect. Tests using get_connection(addr)
        // only work with the legacy connections map.
        let legacy_count = self
            .connections
            .iter()
            .filter(|entry| entry.value().is_connected())
            .count();

        // Note: During migration, both maps may contain connections but we only count
        // the legacy connections to maintain backward compatibility with existing tests

        legacy_count
    }

    /// Get all connected peers - lock-free operation
    pub fn get_connected_peers(&self) -> Vec<SocketAddr> {
        self.connections
            .iter()
            .filter_map(|entry| {
                if entry.value().is_connected() {
                    Some(*entry.key())
                } else {
                    None
                }
            })
            .collect()
    }

    /// Get all connections (including disconnected) - for debugging
    pub fn get_all_connections(&self) -> Vec<SocketAddr> {
        self.connections.iter().map(|entry| *entry.key()).collect()
    }

    /// Get a buffer from the pool or create a new one
    pub fn get_buffer(&mut self, min_capacity: usize) -> Vec<u8> {
        // Use the message buffer pool for lock-free buffer management
        if let Some(buffer) = self.message_buffer_pool.get_buffer() {
            if buffer.capacity() >= min_capacity {
                return buffer;
            }
            // Buffer too small, return it and create new one
            self.message_buffer_pool.return_buffer(buffer);
        }
        Vec::with_capacity(min_capacity.max(1024)) // Minimum 1KB buffers
    }

    /// Return a buffer to the pool for reuse
    pub fn return_buffer(&mut self, buffer: Vec<u8>) {
        if buffer.capacity() >= 1024 && buffer.capacity() <= TCP_BUFFER_SIZE {
            // Return to the lock-free message buffer pool (up to TCP_BUFFER_SIZE)
            self.message_buffer_pool.return_buffer(buffer);
        }
        // Otherwise let the buffer drop
    }

    /// Get a message buffer from the pool for zero-copy processing
    pub fn get_message_buffer(&mut self) -> Vec<u8> {
        self.message_buffer_pool
            .get_buffer()
            .unwrap_or_else(|| Vec::with_capacity(TCP_BUFFER_SIZE / 256)) // Default small buffer
    }

    /// Return a message buffer to the pool
    pub fn return_message_buffer(&mut self, buffer: Vec<u8>) {
        if buffer.capacity() >= 1024 && buffer.capacity() <= TCP_BUFFER_SIZE {
            // Keep buffers with reasonable size (up to TCP_BUFFER_SIZE)
            self.message_buffer_pool.return_buffer(buffer);
        }
        // Otherwise let the buffer drop
    }

    /// Create a message buffer with length header (optimized for reuse)
    pub fn create_message_buffer(&mut self, data: &[u8]) -> Vec<u8> {
        let len = data.len() as u32;
        let mut buffer = self.get_buffer(4 + data.len());
        buffer.extend_from_slice(&len.to_be_bytes());
        buffer.extend_from_slice(data);
        buffer
    }

    /// Get or create a persistent connection to a peer
    /// Fast path: Check for existing connection without creating new ones
    pub fn get_existing_connection(&mut self, addr: SocketAddr) -> Option<ConnectionHandle> {
        let _current_time = current_timestamp();

        if let Some(conn) = self.connections.get_mut(&addr) {
            // The connection here is a mutable reference to Arc<LockFreeConnection>
            if conn.value().is_connected() {
                conn.value().update_last_used();
                debug!(addr = %addr, "using existing persistent connection (fast path)");
                // TODO: ConnectionHandle needs refactoring for lock-free connections
                return None;
            } else {
                // Remove disconnected connection
                debug!(addr = %addr, "removing disconnected connection");
                self.connections.remove(&addr);
            }
        }
        None
    }

    /// Get or create a connection to a node by its ID
    pub async fn get_connection_to_node(&mut self, node_id: &str) -> Result<ConnectionHandle> {
        // Convert string to PeerId for internal use
        let peer_id = crate::PeerId::new(node_id);
        debug!(
            "CONNECTION POOL: get_connection_to_node called for node '{}'",
            node_id
        );

        // First check if we already have a connection to this node
        if let Some(conn_entry) = self.connections_by_peer.get(&peer_id) {
            let conn = conn_entry.value();
            if conn.is_connected() {
                conn.update_last_used();
                debug!(
                    "CONNECTION POOL: Found existing connection to node '{}'",
                    node_id
                );

                if let Some(ref stream_handle) = conn.stream_handle {
                    // Need to get the address for ConnectionHandle
                    let addr = conn.addr;
                    return Ok(ConnectionHandle {
                        addr,
                        stream_handle: stream_handle.clone(),
                        correlation: conn
                            .correlation
                            .clone()
                            .unwrap_or_else(|| CorrelationTracker::new()),
                    });
                } else {
                    return Err(crate::GossipError::Network(std::io::Error::new(
                        std::io::ErrorKind::Other,
                        "Connection exists but no stream handle",
                    )));
                }
            } else {
                // Remove disconnected connection
                debug!(
                    "CONNECTION POOL: Removing disconnected connection to node '{}'",
                    node_id
                );
                drop(conn_entry);
                self.connections_by_peer.remove(&peer_id);
            }
        }

        // Look up the address for this node
        let addr = if let Some(addr_entry) = self.peer_id_to_addr.get(&peer_id) {
            *addr_entry.value()
        } else {
            return Err(crate::GossipError::Network(std::io::Error::new(
                std::io::ErrorKind::NotFound,
                format!("No address configured for node '{}'", node_id),
            )));
        };

        debug!(
            "CONNECTION POOL: Creating new connection to node '{}' at {}",
            node_id, addr
        );

        // Convert PeerId to NodeId for TLS
        let node_id_for_tls = crate::migration::migrate_peer_id_to_node_id(&peer_id).ok();

        // Create the connection and store it by node ID
        // Pass the NodeId so TLS can work even if gossip state doesn't have it yet
        let handle = self
            .get_connection_with_node_id(addr, node_id_for_tls)
            .await?;

        // After successful connection, ensure it's indexed by node ID
        if let Some(conn) = self.connections.get(&addr) {
            self.connections_by_peer
                .insert(peer_id.clone(), conn.value().clone());
            self.addr_to_peer_id.insert(addr, peer_id.clone());
            debug!(
                "CONNECTION POOL: Indexed new connection under node ID '{}'",
                node_id
            );
        }

        Ok(handle)
    }

    pub async fn get_connection(&mut self, addr: SocketAddr) -> Result<ConnectionHandle> {
        self.get_connection_with_node_id(addr, None).await
    }

    pub async fn get_connection_with_node_id(
        &mut self,
        addr: SocketAddr,
        node_id: Option<crate::NodeId>,
    ) -> Result<ConnectionHandle> {
        let _current_time = current_timestamp();
        // Debug logging removed for performance - these logs were too verbose
        // debug!("CONNECTION POOL: get_connection called on pool at {:p} for {}", self as *const _, addr);
        // debug!("CONNECTION POOL: This pool instance has {} connections stored", self.connections.len());

        // TEMPORARY: For backward compatibility, we'll create a hybrid approach
        // that allows the old ConnectionHandle API to work while we transition

        // Check if we already have a lock-free connection
        if let Some(entry) = self.connections.get(&addr) {
            let conn = entry.value();
            if conn.is_connected() {
                conn.update_last_used();
                debug!(addr = %addr, "found existing lock-free connection, creating compatibility handle");

                // Return the existing lock-free connection handle
                if let Some(ref stream_handle) = conn.stream_handle {
                    return Ok(ConnectionHandle {
                        addr,
                        stream_handle: stream_handle.clone(),
                        correlation: conn
                            .correlation
                            .clone()
                            .unwrap_or_else(|| CorrelationTracker::new()),
                    });
                } else {
                    // Connection exists but no stream handle - this shouldn't happen
                    return Err(crate::GossipError::Network(std::io::Error::new(
                        std::io::ErrorKind::Other,
                        "Connection exists but no stream handle",
                    )));
                }
            } else {
                // Remove disconnected connection
                debug!(addr = %addr, "removing disconnected connection");
                drop(entry);
                self.connections.remove(&addr);
            }
        }

        // Extract what we need before any await points to avoid Send issues
        let max_connections = self.max_connections;
        let connection_timeout = self.connection_timeout;
        let registry_weak = self.registry.clone();

        // Make room if necessary - operate on self.connections directly!
        if self.connections.len() >= max_connections {
            let oldest_addr = self
                .connections
                .iter()
                .min_by_key(|entry| entry.value().last_used.load(Ordering::Acquire))
                .map(|entry| *entry.key());

            if let Some(oldest) = oldest_addr {
                self.connections.remove(&oldest);
                warn!(addr = %oldest, "removed oldest connection to make room");
            }
        }

        // Connect with timeout
        debug!("CONNECTION POOL: Attempting to connect to {}", addr);
        let stream = tokio::time::timeout(connection_timeout, TcpStream::connect(addr))
            .await
            .map_err(|_| {
                debug!("CONNECTION POOL: Connection to {} timed out after {:?}", addr, connection_timeout);
                GossipError::Timeout
            })?
            .map_err(|e| {
                debug!("CONNECTION POOL: Connection to {} failed: {} (will retry in {}s if this is a gossip peer)", 
                      addr, e, 5); // 5s is the default retry interval
                GossipError::Network(e)
            })?;
        debug!("CONNECTION POOL: Successfully connected to {}", addr);

        // Configure socket
        stream.set_nodelay(true).map_err(GossipError::Network)?;

        // Check if TLS is enabled
        let (mut reader, writer) = if let Some(registry_arc) =
            registry_weak.as_ref().and_then(|w| w.upgrade())
        {
            if let Some(tls_config) = &registry_arc.tls_config {
                // TLS is enabled - perform handshake as client
                debug!("CONNECTION POOL: TLS enabled, checking for peer NodeId");

                // Use provided NodeId if available, otherwise look it up from gossip state
                let peer_node_id = if node_id.is_some() {
                    node_id
                } else {
                    // Look up the peer's NodeId from the registry's peer info
                    let gossip_state = registry_arc.gossip_state.lock().await;
                    gossip_state
                        .peers
                        .get(&addr)
                        .and_then(|peer_info| peer_info.node_id)
                };

                if let Some(node_id) = peer_node_id {
                    // We have the NodeId - perform TLS handshake
                    debug!(
                        "CONNECTION POOL: Found NodeId for peer {}, performing TLS handshake",
                        addr
                    );

                    // Create DNS name from NodeId
                    let dns_name = crate::tls::name::encode(&node_id);
                    let server_name = rustls::pki_types::ServerName::try_from(dns_name)
                        .map_err(|e| GossipError::TlsError(format!("Invalid DNS name: {}", e)))?;

                    // Create TLS connector
                    info!(
                        "ðŸ” TLS ENABLED: Initiating TLS connection to {} with NodeId {}",
                        addr,
                        node_id.fmt_short()
                    );
                    let connector =
                        tokio_rustls::TlsConnector::from(tls_config.client_config.clone());

                    // Perform TLS handshake
                    match tokio::time::timeout(
                        Duration::from_secs(10),
                        connector.connect(server_name, stream),
                    )
                    .await
                    {
                        Ok(Ok(tls_stream)) => {
                            info!(
                                "âœ… TLS handshake successful with {} (NodeId: {})",
                                addr,
                                node_id.fmt_short()
                            );
                            let (read_half, write_half) = tokio::io::split(tls_stream);
                            (
                                Box::pin(read_half) as Pin<Box<dyn AsyncRead + Send>>,
                                Box::pin(write_half) as Pin<Box<dyn AsyncWrite + Send>>,
                            )
                        }
                        Ok(Err(e)) => {
                            error!(
                                "âŒ TLS handshake failed with {} (expected NodeId: {}): {}",
                                addr,
                                node_id.fmt_short(),
                                e
                            );
                            return Err(GossipError::TlsError(format!(
                                "TLS handshake failed: {}",
                                e
                            )));
                        }
                        Err(_) => {
                            error!(
                                "â±ï¸ TLS handshake timed out with {} (expected NodeId: {})",
                                addr,
                                node_id.fmt_short()
                            );
                            return Err(GossipError::Timeout);
                        }
                    }
                } else {
                    // No NodeId available - can't do TLS, return error instead of panic
                    error!("âŒ TLS is configured but no NodeId available for peer {}. Cannot establish secure connection.", addr);
                    return Err(GossipError::TlsError(format!(
                        "Cannot establish TLS connection to {} without NodeId. Peer may not have connected yet.", 
                        addr
                    )));
                    // COMMENTED OUT: Plain TCP fallback - migrating to TLS-only
                    // let (read_half, write_half) = stream.into_split();
                    // (Box::pin(read_half) as Pin<Box<dyn AsyncRead + Send>>,
                    //  Box::pin(write_half) as Pin<Box<dyn AsyncWrite + Send>>)
                }
            } else {
                // No TLS configured - panic to enforce TLS-only
                panic!("ðŸ”¥ TLS is NOT configured but is required! Cannot establish plain TCP connection to {}", addr);
                // COMMENTED OUT: Plain TCP path - migrating to TLS-only
                // let (read_half, write_half) = stream.into_split();
                // (Box::pin(read_half) as Pin<Box<dyn AsyncRead + Send>>,
                //  Box::pin(write_half) as Pin<Box<dyn AsyncWrite + Send>>)
            }
        } else {
            // No registry reference - panic to enforce TLS requirement
            panic!("ðŸ”¥ No registry reference available - TLS cannot be verified! Cannot establish connection to {}", addr);
            // COMMENTED OUT: Plain TCP fallback - migrating to TLS-only
            // let (read_half, write_half) = stream.into_split();
            // (Box::pin(read_half) as Pin<Box<dyn AsyncRead + Send>>,
            //  Box::pin(write_half) as Pin<Box<dyn AsyncWrite + Send>>)
        };

        // Create lock-free connection for receiving
        let stream_handle = Arc::new(LockFreeStreamHandle::new(
            writer,
            addr,
            ChannelId::Global,
            BufferConfig::default(),
        ));

        let mut conn = LockFreeConnection::new(addr);
        conn.stream_handle = Some(stream_handle.clone());
        conn.set_state(ConnectionState::Connected);
        conn.update_last_used();

        // For outgoing connections, we might know the peer ID from configuration
        let peer_id_opt = self
            .addr_to_peer_id
            .get(&addr)
            .map(|entry| entry.clone())
            .or_else(|| {
                // Try reverse lookup: find peer ID that maps to this address
                self.peer_id_to_addr
                    .iter()
                    .find(|entry| entry.value() == &addr)
                    .map(|entry| entry.key().clone())
            });

        if let Some(peer_id) = peer_id_opt {
            // Use shared correlation tracker for this peer
            conn.correlation = Some(self.get_or_create_correlation_tracker(&peer_id));
            debug!(
                "CONNECTION POOL: Using shared correlation tracker for peer {:?} at {}",
                peer_id, addr
            );
        } else {
            // No peer ID yet, create a new correlation tracker
            // This will be replaced when we learn the peer ID from their FullSync message
            conn.correlation = Some(CorrelationTracker::new());
            debug!(
                "CONNECTION POOL: Created new correlation tracker for unknown peer at {}",
                addr
            );
        }

        let connection_arc = Arc::new(conn);

        // Insert into lock-free map before spawning
        self.connections.insert(addr, connection_arc.clone());
        debug!("CONNECTION POOL: Added connection via get_connection to {} - pool now has {} connections", 
              addr, self.connections.len());
        // Double check it's really there
        assert!(
            self.connections.contains_key(&addr),
            "Connection was not added to pool!"
        );
        debug!("CONNECTION POOL: Verified connection exists for {}", addr);

        // Send initial FullSync message to identify ourselves
        if let Some(registry_arc) = registry_weak.as_ref().and_then(|w| w.upgrade()) {
            let initial_msg = {
                let actor_state = registry_arc.actor_state.read().await;
                let gossip_state = registry_arc.gossip_state.lock().await;

                RegistryMessage::FullSync {
                    local_actors: actor_state
                        .local_actors
                        .clone()
                        .into_iter()
                        .map(|(k, v)| (k, v))
                        .collect(),
                    known_actors: actor_state
                        .known_actors
                        .clone()
                        .into_iter()
                        .map(|(k, v)| (k, v))
                        .collect(),
                    sender_peer_id: registry_arc.peer_id.clone(),
                    sequence: gossip_state.gossip_sequence,
                    wall_clock_time: crate::current_timestamp(),
                }
            };

            // Serialize and send the initial message with Gossip type prefix
            match rkyv::to_bytes::<rkyv::rancor::Error>(&initial_msg) {
                Ok(data) => {
                    // Create message with type prefix for gossip messages
                    let mut msg_buffer = Vec::with_capacity(4 + 1 + data.len());
                    msg_buffer.extend_from_slice(&((1 + data.len()) as u32).to_be_bytes()); // Length includes type byte
                    msg_buffer.push(crate::MessageType::Gossip as u8); // Add Gossip type
                    msg_buffer.extend_from_slice(&data);

                    // Create a connection handle to send the message
                    let conn_handle = ConnectionHandle {
                        addr,
                        stream_handle: stream_handle.clone(),
                        correlation: connection_arc
                            .correlation
                            .clone()
                            .unwrap_or_else(|| CorrelationTracker::new()),
                    };
                    if let Err(e) = conn_handle.send_data(msg_buffer).await {
                        warn!(peer = %addr, error = %e, "Failed to send initial FullSync message");
                    } else {
                        info!(peer = %addr, "Sent initial FullSync message to identify ourselves");
                    }
                }
                Err(e) => {
                    warn!(peer = %addr, error = %e, "Failed to serialize initial FullSync message");
                }
            }
        }

        // Note: actor_message_handler is fetched from registry on each message to handle
        // cases where the handler is registered after connection establishment

        // Spawn reader task for outgoing connection
        // This MUST process incoming messages to receive responses!
        let reader_connection = connection_arc.clone();
        let registry_weak_for_reader = registry_weak.clone();
        tokio::spawn(async move {
            use tokio::io::AsyncReadExt;
            info!(peer = %addr, "Starting outgoing connection reader with message processing");

            let mut partial_msg_buf = Vec::new();
            // Increase buffer size to handle large messages more efficiently
            // 1MB buffer can read 35MB message in ~35 chunks instead of ~8500
            let mut read_buf = vec![0u8; 1024 * 1024]; // 1MB read buffer

            loop {
                match reader.read(&mut read_buf).await {
                    Ok(0) => {
                        reader_connection.set_state(ConnectionState::Disconnected);
                        info!(peer = %addr, "Outgoing connection closed by peer (EOF)");
                        // Check if connection is still in pool
                        if let Some(ref registry_weak) = registry_weak_for_reader {
                            if let Some(registry) = registry_weak.upgrade() {
                                let pool = registry.connection_pool.lock().await;
                                info!(peer = %addr, "Connection still in pool after EOF? {}", 
                                      pool.connections.contains_key(&addr));
                            }
                        }
                        break;
                    }
                    Ok(n) => {
                        partial_msg_buf.extend_from_slice(&read_buf[..n]);

                        // Process complete messages
                        while partial_msg_buf.len() >= 4 {
                            let len = u32::from_be_bytes([
                                partial_msg_buf[0],
                                partial_msg_buf[1],
                                partial_msg_buf[2],
                                partial_msg_buf[3],
                            ]) as usize;

                            if partial_msg_buf.len() >= 4 + len {
                                // We have a complete message
                                let msg_data = &partial_msg_buf[4..4 + len];

                                // Log message for debugging large messages
                                if len > 1024 * 1024 {
                                    // > 1MB
                                    info!(peer = %addr, msg_size = len, "âœ… COMPLETE: Large message fully received, processing...");
                                }

                                // Check if this is an Ask/Response message by looking at first byte
                                if msg_data.len() >= 1 {
                                    if let Some(msg_type) =
                                        crate::MessageType::from_byte(msg_data[0])
                                    {
                                        debug!(peer = %addr, msg_type = ?msg_type, "Identified message type: {:?}", msg_type);
                                        // This is an Ask/Response message
                                        if msg_data.len() < 8 {
                                            warn!(peer = %addr, "Ask/Response message too small");
                                            partial_msg_buf.drain(..4 + len);
                                            continue;
                                        }

                                        let correlation_id =
                                            u16::from_be_bytes([msg_data[1], msg_data[2]]);
                                        let payload = &msg_data[8..];

                                        match msg_type {
                                            crate::MessageType::Ask => {
                                                // Handle incoming Ask requests for testing
                                                #[cfg(feature = "test-helpers")]
                                                {
                                                    if let Some(ref registry_weak) =
                                                        registry_weak_for_reader
                                                    {
                                                        if let Some(registry) =
                                                            registry_weak.upgrade()
                                                        {
                                                            let conn = {
                                                                let pool = registry
                                                                    .connection_pool
                                                                    .lock()
                                                                    .await;
                                                                pool.connections.get(&addr).map(
                                                                    |conn_ref| {
                                                                        conn_ref.value().clone()
                                                                    },
                                                                )
                                                            };

                                                            if let Some(conn) = conn {
                                                                // Process the request and generate response
                                                                let request_str =
                                                                    String::from_utf8_lossy(
                                                                        payload,
                                                                    );
                                                                let response = process_mock_request(
                                                                    &request_str,
                                                                );

                                                                // Send response back
                                                                if let Some(ref stream_handle) =
                                                                    conn.stream_handle
                                                                {
                                                                    let mut msg = bytes::BytesMut::with_capacity(4 + 8 + response.len());
                                                                    let total_size =
                                                                        8 + response.len();
                                                                    msg.extend_from_slice(
                                                                        &(total_size as u32)
                                                                            .to_be_bytes(),
                                                                    );
                                                                    msg.put_u8(
                                                                        crate::MessageType::Response
                                                                            as u8,
                                                                    );
                                                                    msg.extend_from_slice(
                                                                        &correlation_id
                                                                            .to_be_bytes(),
                                                                    );
                                                                    msg.extend_from_slice(
                                                                        &[0u8; 5],
                                                                    );
                                                                    msg.extend_from_slice(
                                                                        &response,
                                                                    );

                                                                    if let Err(e) = stream_handle
                                                                        .write_bytes_nonblocking(
                                                                            msg.freeze(),
                                                                        )
                                                                    {
                                                                        warn!(peer = %addr, error = %e, "Failed to send Ask response");
                                                                    } else {
                                                                        debug!(peer = %addr, correlation_id = correlation_id, "Sent Ask response");
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                                #[cfg(not(feature = "test-helpers"))]
                                                {
                                                    warn!(peer = %addr, correlation_id = correlation_id, "Received Ask request - not implemented in production");
                                                }
                                            }
                                            crate::MessageType::Response => {
                                                // Handle incoming response - DIRECT DELIVERY, NO LOCKS OR SEARCHES
                                                debug!(peer = %addr, correlation_id = correlation_id, "Received response message");

                                                // Use the correlation tracker directly from the connection
                                                if let Some(ref correlation) =
                                                    reader_connection.correlation
                                                {
                                                    if correlation.has_pending(correlation_id) {
                                                        correlation.complete(
                                                            correlation_id,
                                                            payload.to_vec(),
                                                        );
                                                        debug!(peer = %addr, correlation_id = correlation_id, 
                                                               "Delivered response via correlation tracker");
                                                    } else {
                                                        debug!(peer = %addr, correlation_id = correlation_id, 
                                                               "No pending request for this correlation_id - may have timed out");
                                                    }
                                                } else {
                                                    warn!(peer = %addr, correlation_id = correlation_id, 
                                                           "Connection has no correlation tracker!");
                                                }
                                            }
                                            crate::MessageType::Gossip => {
                                                // Gossip messages can arrive here, just ignore them
                                            }
                                            crate::MessageType::ActorTell => {
                                                // Direct actor tell message format:
                                                // Already parsed: [type:1][correlation_id:2][reserved:5]
                                                // Payload: [actor_id:8][type_hash:4][payload_len:4][payload:N]
                                                eprintln!("[SERVER] ðŸ” Received ActorTell message from {}, payload len: {}", addr, payload.len());
                                                if payload.len() >= 16 {
                                                    let actor_id = u64::from_be_bytes(
                                                        payload[0..8].try_into().unwrap(),
                                                    );
                                                    let type_hash = u32::from_be_bytes(
                                                        payload[8..12].try_into().unwrap(),
                                                    );
                                                    let payload_len = u32::from_be_bytes(
                                                        payload[12..16].try_into().unwrap(),
                                                    )
                                                        as usize;

                                                    info!(peer = %addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash), 
                                                          payload_len = payload_len, "ðŸ“¨ ActorTell message details");

                                                    if payload.len() >= 16 + payload_len {
                                                        let actor_payload =
                                                            &payload[16..16 + payload_len];
                                                        info!(peer = %addr, actual_payload_size = actor_payload.len(), "âœ… ActorTell payload size check passed");

                                                        // Fetch actor message handler from registry each time (in case it's set after connection)
                                                        if let Some(ref registry_weak) =
                                                            registry_weak_for_reader
                                                        {
                                                            if let Some(registry) =
                                                                registry_weak.upgrade()
                                                            {
                                                                if let Some(ref handler) =
                                                                    &*registry
                                                                        .actor_message_handler
                                                                        .lock()
                                                                        .await
                                                                {
                                                                    info!(peer = %addr, "ðŸš€ Calling actor message handler for ActorTell");
                                                                    match handler
                                                                        .handle_actor_message(
                                                                            &actor_id.to_string(),
                                                                            type_hash,
                                                                            actor_payload,
                                                                            None, // No correlation for tell
                                                                        )
                                                                        .await
                                                                    {
                                                                        Ok(_) => {
                                                                            info!(peer = %addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash), 
                                                                                       "âœ… ActorTell handled successfully")
                                                                        }
                                                                        Err(e) => {
                                                                            error!(peer = %addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash), 
                                                                                         error = %e, "âŒ Failed to handle ActorTell")
                                                                        }
                                                                    }
                                                                } else {
                                                                    error!(peer = %addr, "âŒ No actor message handler registered in registry");
                                                                }
                                                            } else {
                                                                error!(peer = %addr, "âŒ Registry weak reference could not be upgraded");
                                                            }
                                                        } else {
                                                            error!(peer = %addr, "âŒ No registry weak reference available");
                                                        }
                                                    } else {
                                                        error!(peer = %addr, expected = 16 + payload_len, actual = payload.len(), 
                                                              "âŒ ActorTell payload too short");
                                                    }
                                                } else {
                                                    error!(peer = %addr, payload_len = payload.len(), "âŒ ActorTell header too short");
                                                }
                                            }
                                            crate::MessageType::ActorAsk => {
                                                // TODO: Implement ActorAsk handling
                                                warn!(peer = %addr, "ActorAsk not yet implemented");
                                            }
                                            crate::MessageType::StreamStart => {
                                                // Parse stream header from payload
                                                if payload.len()
                                                    >= crate::StreamHeader::SERIALIZED_SIZE
                                                {
                                                    if let Some(header) =
                                                        crate::StreamHeader::from_bytes(&payload)
                                                    {
                                                        info!(peer = %addr, stream_id = header.stream_id, total_size = header.total_size,
                                                              type_hash = %format!("{:08x}", header.type_hash), actor_id = header.actor_id,
                                                              "ðŸ“¥ StreamStart: Beginning streaming transfer");

                                                        // Initialize stream assembly
                                                        if let Some(ref registry_weak) =
                                                            registry_weak_for_reader
                                                        {
                                                            if let Some(registry) =
                                                                registry_weak.upgrade()
                                                            {
                                                                registry
                                                                    .start_stream_assembly(header)
                                                                    .await;
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            crate::MessageType::StreamData => {
                                                // Parse stream header and data
                                                if payload.len()
                                                    >= crate::StreamHeader::SERIALIZED_SIZE
                                                {
                                                    if let Some(header) =
                                                        crate::StreamHeader::from_bytes(&payload)
                                                    {
                                                        let data_start =
                                                            crate::StreamHeader::SERIALIZED_SIZE;
                                                        if payload.len()
                                                            >= data_start
                                                                + header.chunk_size as usize
                                                        {
                                                            let chunk_data = &payload[data_start
                                                                ..data_start
                                                                    + header.chunk_size as usize];

                                                            debug!(peer = %addr, stream_id = header.stream_id, chunk_index = header.chunk_index,
                                                                   chunk_size = header.chunk_size, "ðŸ“¦ StreamData: Received chunk");

                                                            // Add chunk to stream assembly
                                                            if let Some(ref registry_weak) =
                                                                registry_weak_for_reader
                                                            {
                                                                if let Some(registry) =
                                                                    registry_weak.upgrade()
                                                                {
                                                                    registry
                                                                        .add_stream_chunk(
                                                                            header,
                                                                            chunk_data.to_vec(),
                                                                        )
                                                                        .await;
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            crate::MessageType::StreamEnd => {
                                                // Parse stream header and complete assembly
                                                if payload.len()
                                                    >= crate::StreamHeader::SERIALIZED_SIZE
                                                {
                                                    if let Some(header) =
                                                        crate::StreamHeader::from_bytes(&payload)
                                                    {
                                                        info!(peer = %addr, stream_id = header.stream_id,
                                                              "ðŸ“¤ StreamEnd: Completing streaming transfer");

                                                        // Complete stream assembly and deliver to actor
                                                        if let Some(ref registry_weak) =
                                                            registry_weak_for_reader
                                                        {
                                                            if let Some(registry) =
                                                                registry_weak.upgrade()
                                                            {
                                                                if let Some(complete_msg) = registry
                                                                    .complete_stream_assembly(
                                                                        header.stream_id,
                                                                    )
                                                                    .await
                                                                {
                                                                    // Deliver to actor
                                                                    if let Some(ref handler) =
                                                                        &*registry
                                                                            .actor_message_handler
                                                                            .lock()
                                                                            .await
                                                                    {
                                                                        match handler
                                                                            .handle_actor_message(
                                                                                &header
                                                                                    .actor_id
                                                                                    .to_string(),
                                                                                header.type_hash,
                                                                                &complete_msg,
                                                                                None,
                                                                            )
                                                                            .await
                                                                        {
                                                                            Ok(_) => {
                                                                                info!(peer = %addr, stream_id = header.stream_id,
                                                                                          "âœ… Successfully delivered streamed message to actor")
                                                                            }
                                                                            Err(e) => {
                                                                                error!(peer = %addr, stream_id = header.stream_id,
                                                                                            error = %e, "âŒ Failed to deliver streamed message")
                                                                            }
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }

                                        partial_msg_buf.drain(..4 + len);
                                        continue;
                                    }
                                }

                                // This could be either a gossip message or a raw tell message
                                // Gossip messages should deserialize as RegistryMessage
                                // Tell messages are raw actor messages without type prefix
                                let msg_data_vec = msg_data.to_vec();

                                // First drain the buffer to ensure proper alignment for next message
                                partial_msg_buf.drain(..4 + len);

                                // Process the message if we have a registry
                                if let Some(ref registry_weak) = registry_weak_for_reader {
                                    if let Some(registry) = registry_weak.upgrade() {
                                        // Try to deserialize as RegistryMessage for gossip protocol
                                        match rkyv::from_bytes::<RegistryMessage, rkyv::rancor::Error>(
                                            &msg_data_vec,
                                        ) {
                                            Ok(msg) => {
                                                debug!(peer = %addr, "Received gossip message on outgoing connection");

                                                // Extract node ID from message if available
                                                let node_id = match &msg {
                                                    RegistryMessage::FullSync {
                                                        sender_peer_id,
                                                        ..
                                                    } => Some(sender_peer_id.as_str().to_string()),
                                                    RegistryMessage::FullSyncResponse {
                                                        sender_peer_id,
                                                        ..
                                                    } => Some(sender_peer_id.as_str().to_string()),
                                                    _ => None,
                                                };

                                                // NOTE: We do NOT update node address mapping here because 'addr' is the
                                                // address we connected TO, which is the correct bind address. We don't want
                                                // to accidentally overwrite it with ephemeral ports from other connections.
                                                if let Some(node_id) = node_id {
                                                    debug!(peer = %addr, node_id = %node_id, "Received message from node on outgoing connection");
                                                }

                                                if let Err(e) =
                                                    handle_incoming_message(registry, addr, msg)
                                                        .await
                                                {
                                                    warn!(peer = %addr, error = %e, "Failed to handle message on outgoing connection");
                                                }
                                            }
                                            Err(e) => {
                                                // This might be a raw tell message without gossip wrapping
                                                // Log at debug level since this is expected for tell messages
                                                debug!(peer = %addr, error = %e, msg_len = msg_data_vec.len(), 
                                                       "Message is not a RegistryMessage, might be a raw actor tell message");
                                                // Don't drop connection, just continue processing
                                            }
                                        }
                                    }
                                }
                            } else {
                                // Need more data
                                break;
                            }
                        }
                    }
                    Err(e) => {
                        reader_connection.set_state(ConnectionState::Failed);
                        warn!(peer = %addr, error = %e, "Outgoing connection error");
                        break;
                    }
                }
            }

            info!(peer = %addr, "Outgoing connection reader exited");
        });

        // Reset failure state for this peer since we successfully connected
        if let Some(ref registry_weak) = registry_weak {
            if let Some(registry) = registry_weak.upgrade() {
                let registry_clone = registry.clone();
                let peer_addr = addr;
                tokio::spawn(async move {
                    let mut gossip_state = registry_clone.gossip_state.lock().await;

                    // Check if we need to reset failures and clear pending
                    let need_to_clear_pending = if let Some(peer_info) =
                        gossip_state.peers.get_mut(&peer_addr)
                    {
                        let had_failures = peer_info.failures > 0;
                        if had_failures {
                            info!(peer = %peer_addr, 
                                  prev_failures = peer_info.failures,
                                  "âœ… Successfully established outgoing connection - resetting failure state");
                            peer_info.failures = 0;
                            peer_info.last_failure_time = None;
                        }
                        peer_info.last_success = crate::current_timestamp();
                        had_failures
                    } else {
                        false
                    };

                    // Clear pending failure record if needed
                    if need_to_clear_pending {
                        gossip_state.pending_peer_failures.remove(&peer_addr);
                    }
                });
            }
        }

        info!(peer = %addr, "successfully created new persistent connection");

        // Verify the connection is in the pool
        debug!(
            "CONNECTION POOL: After get_connection, pool has {} connections",
            self.connections.len()
        );
        debug!(
            "CONNECTION POOL: Pool contains connection to {}? {}",
            addr,
            self.connections.contains_key(&addr)
        );

        // Return a lock-free ConnectionHandle
        Ok(ConnectionHandle {
            addr,
            stream_handle: stream_handle,
            correlation: connection_arc
                .correlation
                .clone()
                .unwrap_or_else(|| CorrelationTracker::new()),
        })
    }

    /// Mark a connection as disconnected
    pub fn mark_disconnected(&mut self, addr: SocketAddr) {
        if let Some(entry) = self.connections.get(&addr) {
            entry.value().set_state(ConnectionState::Disconnected);
            info!(peer = %addr, "marked connection as disconnected");
        }
    }

    /// Remove a connection from the pool by address (old method for compatibility)
    pub fn remove_connection_mut(&mut self, addr: SocketAddr) {
        if let Some(_conn) = self.connections.remove(&addr) {
            info!(addr = %addr, "removed connection from pool");
            // Dropping the sender will cause the receiver to return None,
            // signaling the connection handler to shut down
            // No need to drop writer
        }
    }

    /// Get number of active connections (old method for compatibility)
    pub fn connection_count_old(&self) -> usize {
        self.connections
            .iter()
            .filter(|entry| entry.value().is_connected())
            .count()
    }

    /// Check if we have a connection to a peer by address
    pub fn has_connection(&self, addr: &SocketAddr) -> bool {
        self.connections
            .get(addr)
            .map(|entry| entry.value().is_connected())
            .unwrap_or(false)
    }

    /// Check health of all connections (for compatibility)
    pub async fn check_connection_health(&mut self) -> Vec<SocketAddr> {
        // Health checking is now done by the persistent connection handlers
        Vec::new()
    }

    /// Clean up stale connections
    pub fn cleanup_stale_connections(&mut self) {
        let to_remove: Vec<_> = self
            .connections
            .iter()
            .filter(|entry| !entry.value().is_connected())
            .map(|entry| *entry.key())
            .collect();

        for addr in to_remove {
            self.connections.remove(&addr);
            debug!(addr = %addr, "cleaned up disconnected connection");
        }
    }

    /// Close all connections (for shutdown)
    pub fn close_all_connections(&mut self) {
        let addrs: Vec<_> = self.connections.iter().map(|entry| *entry.key()).collect();
        let count = addrs.len();
        for addr in addrs {
            self.remove_connection(addr);
        }
        info!("closed all {} connections", count);
    }
}

/// Start a persistent connection handler in the background
fn start_persistent_connection_reader(
    reader: tokio::net::tcp::OwnedReadHalf,
    writer: Option<tokio::net::tcp::OwnedWriteHalf>,
    peer_addr: SocketAddr,
    registry_weak: Option<std::sync::Weak<GossipRegistry>>,
) {
    tokio::spawn(async move {
        handle_persistent_connection_reader(reader, writer, peer_addr, registry_weak).await;
    });
}

/// Handle an incoming persistent connection - processes messages with direct TCP
pub(crate) async fn handle_incoming_persistent_connection(
    stream: TcpStream,
    _rx: mpsc::Receiver<Vec<u8>>,
    _peer_addr: SocketAddr,
    listening_addr: SocketAddr,
    registry_weak: Option<std::sync::Weak<GossipRegistry>>,
) {
    let (reader, writer) = stream.into_split();

    // Pass the writer along to be stored when we know the node ID
    handle_persistent_connection_reader(reader, Some(writer), listening_addr, registry_weak).await;
}

/// Handle persistent connection reader - only reads messages, no channels
pub(crate) async fn handle_persistent_connection_reader(
    mut reader: tokio::net::tcp::OwnedReadHalf,
    writer: Option<tokio::net::tcp::OwnedWriteHalf>,
    peer_addr: SocketAddr,
    registry_weak: Option<std::sync::Weak<GossipRegistry>>,
) {
    use tokio::io::AsyncReadExt;

    let mut partial_msg_buf = Vec::new();
    // Increase buffer size to handle large messages more efficiently
    let mut read_buf = vec![0u8; 1024 * 1024]; // 1MB read buffer

    // For incoming connections with a writer, create a stream handle
    // For outgoing connections, we'll use the existing handle from the pool
    let response_handle = if let Some(writer) = writer {
        Some(Arc::new(LockFreeStreamHandle::new(
            writer,
            peer_addr,
            ChannelId::Global,
            BufferConfig::default(),
        )))
    } else {
        None
    };

    loop {
        match reader.read(&mut read_buf).await {
            Ok(0) => {
                info!(peer = %peer_addr, "Connection closed by peer");
                break;
            }
            Ok(n) => {
                partial_msg_buf.extend_from_slice(&read_buf[..n]);

                // Process complete messages
                while partial_msg_buf.len() >= 4 {
                    let len = u32::from_be_bytes([
                        partial_msg_buf[0],
                        partial_msg_buf[1],
                        partial_msg_buf[2],
                        partial_msg_buf[3],
                    ]) as usize;

                    if len > 100 * 1024 * 1024 {
                        warn!(peer = %peer_addr, len = len, "Message too large - possible buffer corruption");
                        // This usually indicates we're reading from the wrong position in the buffer
                        // Clear the buffer completely and restart message processing
                        partial_msg_buf.clear();
                        break;
                    }

                    // Debug log for large messages (>1MB)
                    if len > 1024 * 1024 {
                        // eprintln!("ðŸ“¦ SERVER: LARGE MESSAGE detected! len={}, from peer={}", len, peer_addr);
                        // info!(peer = %peer_addr, len = len, buf_len = partial_msg_buf.len(), needed = 4 + len,
                        //       "ðŸ“¦ LARGE MESSAGE: Receiving large message (have {} of {} bytes)",
                        //       partial_msg_buf.len(), 4 + len);

                        // Pre-allocate buffer capacity for large messages to avoid repeated allocations
                        let total_needed = 4 + len;
                        if partial_msg_buf.capacity() < total_needed {
                            partial_msg_buf.reserve(total_needed - partial_msg_buf.len());
                            info!(peer = %peer_addr, "ðŸ“¦ LARGE MESSAGE: Reserved {} bytes for message", total_needed);
                        }
                    }

                    let total_len = 4 + len;
                    if partial_msg_buf.len() < total_len {
                        // if len > 1024 * 1024 {
                        //     eprintln!("ðŸ“¦ SERVER: Accumulating large message... have {}/{} bytes", partial_msg_buf.len(), total_len);
                        // }
                        // Not enough data yet, break inner loop to read more
                        break;
                    }
                    if partial_msg_buf.len() >= total_len {
                        let msg_data = &partial_msg_buf[4..total_len];

                        // Log when we have the complete large message
                        // if len > 1024 * 1024 {
                        //     eprintln!("ðŸ“¦ SERVER: LARGE MESSAGE COMPLETE! len={}, processing...", len);
                        //     // info!(peer = %peer_addr, len = len, "ðŸ“¦ LARGE MESSAGE: Complete message received, processing...");
                        // }

                        // Debug: Log first few bytes of every message
                        if msg_data.len() >= 8 {
                            info!(peer = %peer_addr, 
                                  "ðŸ” SERVER RECV: msg_len={}, first_bytes=[{:02x} {:02x} {:02x} {:02x} {:02x} {:02x} {:02x} {:02x}]",
                                  msg_data.len(), 
                                  msg_data[0], msg_data[1], msg_data[2], msg_data[3],
                                  msg_data[4], msg_data[5], msg_data[6], msg_data[7]);
                        }

                        // Check if this is an Ask/Response message by looking at first byte
                        if msg_data.len() >= 1 {
                            // Debug log for large messages
                            // if len > 1024 * 1024 {
                            //     info!(peer = %peer_addr, first_byte = msg_data[0], "ðŸ“¦ LARGE MESSAGE first byte: {} (0=Gossip, 3=ActorTell)", msg_data[0]);
                            // }
                            if let Some(msg_type) = crate::MessageType::from_byte(msg_data[0]) {
                                // This is an Ask/Response message
                                if msg_data.len() < 8 {
                                    warn!(peer = %peer_addr, "Ask/Response message too small");
                                    partial_msg_buf.drain(..total_len);
                                    continue;
                                }

                                let correlation_id = u16::from_be_bytes([msg_data[1], msg_data[2]]);
                                let payload = &msg_data[8..];

                                match msg_type {
                                    crate::MessageType::Ask => {
                                        info!(peer = %peer_addr, correlation_id = correlation_id, payload_len = payload.len(),
                                              "ðŸ“¨ ASK DEBUG: Received Ask message on bidirectional connection");

                                        // Try to deserialize the payload as a RegistryMessage
                                        // Note: payload might not be aligned, so we need to copy it to an aligned buffer
                                        let aligned_payload = payload.to_vec();
                                        match rkyv::from_bytes::<
                                            crate::registry::RegistryMessage,
                                            rkyv::rancor::Error,
                                        >(
                                            &aligned_payload
                                        ) {
                                            Ok(mut registry_msg) => {
                                                info!(peer = %peer_addr, correlation_id = correlation_id, 
                                                      "âœ… ASK DEBUG: Successfully deserialized RegistryMessage");
                                                debug!(peer = %peer_addr, correlation_id = correlation_id, "Received Ask with RegistryMessage payload");

                                                // If it's an ActorMessage, ensure it has the correlation_id from the Ask envelope
                                                if let crate::registry::RegistryMessage::ActorMessage {
                                                ref actor_id,
                                                ref type_hash,
                                                payload: _,
                                                correlation_id: ref mut inner_correlation_id,
                                            } = registry_msg {
                                                if inner_correlation_id.is_none() {
                                                    // Use the Ask envelope's correlation_id
                                                    *inner_correlation_id = Some(correlation_id);
                                                    debug!(
                                                        peer = %peer_addr, 
                                                        correlation_id = correlation_id,
                                                        actor_id = %actor_id,
                                                        type_hash = %format!("{:08x}", type_hash),
                                                        "Set ActorMessage correlation_id from Ask envelope"
                                                    );
                                                }
                                            }

                                                // Handle the registry message and get the response
                                                // For Ask messages, we need to handle the reply ourselves
                                                if let Some(ref registry_weak) = registry_weak {
                                                    if let Some(registry) = registry_weak.upgrade()
                                                    {
                                                        // Special handling for ActorMessage with correlation_id
                                                        if let crate::registry::RegistryMessage::ActorMessage { 
                                                        ref actor_id, 
                                                        ref type_hash, 
                                                        ref payload,
                                                        correlation_id: Some(corr_id),
                                                    } = registry_msg {
                                                        info!(peer = %peer_addr, actor_id = %actor_id, type_hash = %format!("{:08x}", type_hash),
                                                              payload_len = payload.len(), correlation_id = corr_id,
                                                              "ðŸŽ¯ ASK DEBUG: Processing ActorMessage ask");
                                                        // Handle the actor message directly
                                                        match registry.handle_actor_message(actor_id, *type_hash, payload, Some(corr_id)).await {
                                                            Ok(Some(reply_payload)) => {
                                                                debug!(peer = %peer_addr, correlation_id = corr_id, reply_len = reply_payload.len(),
                                                                       "Got reply from actor, sending response back");
                                                                
                                                                // Create response message
                                                                let mut response = bytes::BytesMut::with_capacity(4 + 8 + reply_payload.len());
                                                                
                                                                // Length prefix (4 bytes)
                                                                let total_len = 8 + reply_payload.len() as u32;
                                                                response.extend_from_slice(&total_len.to_be_bytes());
                                                                
                                                                // 8-byte header: msg_type(1) + correlation_id(2) + reserved(5)
                                                                response.put_u8(crate::MessageType::Response as u8);
                                                                response.extend_from_slice(&corr_id.to_be_bytes());
                                                                response.extend_from_slice(&[0u8; 5]);
                                                                
                                                                // Payload
                                                                response.extend_from_slice(&reply_payload);
                                                                
                                                                // For both incoming and outgoing connections, find the stream handle from the pool
                                                                let pool = registry.connection_pool.lock().await;
                                                                if let Some(conn) = pool.connections.get(&peer_addr).map(|c| c.value().clone()) {
                                                                    if let Some(ref stream_handle) = conn.stream_handle {
                                                                        if let Err(e) = stream_handle.write_bytes_nonblocking(response.freeze()) {
                                                                            warn!(peer = %peer_addr, error = %e, "Failed to send ask reply");
                                                                        } else {
                                                                            debug!(peer = %peer_addr, correlation_id = corr_id, "Sent ask reply through connection pool");
                                                                        }
                                                                    } else {
                                                                        warn!(peer = %peer_addr, "Connection has no stream handle");
                                                                    }
                                                                } else {
                                                                    warn!(peer = %peer_addr, "No connection found in pool to send ask reply");
                                                                }
                                                            }
                                                            Ok(None) => {
                                                                debug!(peer = %peer_addr, correlation_id = corr_id, "No reply from actor");
                                                            }
                                                            Err(e) => {
                                                                warn!(peer = %peer_addr, error = %e, correlation_id = corr_id, "Failed to handle actor message");
                                                            }
                                                        }
                                                    } else {
                                                        // For other messages, use the normal handler
                                                        match handle_incoming_message(registry.clone(), peer_addr, registry_msg).await {
                                                        Ok(()) => {
                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, "Ask message processed");
                                                        }
                                                        Err(e) => {
                                                            warn!(peer = %peer_addr, error = %e, correlation_id = correlation_id, "Failed to handle Ask message");
                                                        }
                                                    }
                                                    }
                                                    }
                                                }
                                            }
                                            Err(e) => {
                                                warn!(peer = %peer_addr, correlation_id = correlation_id, error = %e,
                                                       payload_len = payload.len(),
                                                       "HANDLE ASK: Failed to deserialize as RegistryMessage, trying MessageWrapper");

                                                // Not a RegistryMessage, handle as before for test helpers
                                                #[cfg(feature = "test-helpers")]
                                                {
                                                    if let Some(ref registry_weak) = registry_weak {
                                                        if let Some(registry) =
                                                            registry_weak.upgrade()
                                                        {
                                                            let conn = {
                                                                let pool = registry
                                                                    .connection_pool
                                                                    .lock()
                                                                    .await;
                                                                pool.connections
                                                                    .get(&peer_addr)
                                                                    .map(|conn_ref| {
                                                                        conn_ref.value().clone()
                                                                    })
                                                            };

                                                            if let Some(conn) = conn {
                                                                // Process the request and generate response
                                                                let request_str =
                                                                    String::from_utf8_lossy(
                                                                        payload,
                                                                    );
                                                                let response_data =
                                                                    process_mock_request(
                                                                        &request_str,
                                                                    );

                                                                // Build response message
                                                                let total_size =
                                                                    8 + response_data.len();
                                                                let mut msg =
                                                                    bytes::BytesMut::with_capacity(
                                                                        4 + total_size,
                                                                    );

                                                                // Length prefix
                                                                msg.extend_from_slice(
                                                                    &(total_size as u32)
                                                                        .to_be_bytes(),
                                                                );

                                                                // Header: [type:1][corr_id:2][reserved:5]
                                                                msg.put_u8(
                                                                    crate::MessageType::Response
                                                                        as u8,
                                                                );
                                                                msg.extend_from_slice(
                                                                    &correlation_id.to_be_bytes(),
                                                                );
                                                                msg.extend_from_slice(&[0u8; 5]);
                                                                msg.extend_from_slice(
                                                                    &response_data,
                                                                );

                                                                // Send response back through stream handle
                                                                if let Some(ref stream_handle) =
                                                                    conn.stream_handle
                                                                {
                                                                    if let Err(e) = stream_handle
                                                                        .write_bytes_nonblocking(
                                                                            msg.freeze(),
                                                                        )
                                                                    {
                                                                        warn!("Failed to send mock response: {}", e);
                                                                    } else {
                                                                        debug!("Sent mock response for correlation_id {}", correlation_id);
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                                #[cfg(not(feature = "test-helpers"))]
                                                {
                                                    // This might be a kameo AskWrapper - try to handle it
                                                    debug!(peer = %peer_addr, correlation_id = correlation_id, payload_len = payload.len(), 
                                                      "Received non-RegistryMessage Ask request, checking if it's from kameo");

                                                    // Try to parse binary format from kameo: [actor_id:8][type_hash:4][payload_len:4][payload:N]
                                                    if payload.len() >= 16 {
                                                        let actor_id = u64::from_be_bytes([
                                                            payload[0], payload[1], payload[2],
                                                            payload[3], payload[4], payload[5],
                                                            payload[6], payload[7],
                                                        ]);
                                                        let type_hash = u32::from_be_bytes([
                                                            payload[8],
                                                            payload[9],
                                                            payload[10],
                                                            payload[11],
                                                        ]);
                                                        let payload_len = u32::from_be_bytes([
                                                            payload[12],
                                                            payload[13],
                                                            payload[14],
                                                            payload[15],
                                                        ])
                                                            as usize;

                                                        if payload.len() >= 16 + payload_len {
                                                            let inner_payload =
                                                                &payload[16..16 + payload_len];

                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, 
                                                               actor_id = actor_id, type_hash = type_hash,
                                                               "Successfully decoded kameo binary message format");

                                                            if let Some(ref registry_weak) =
                                                                registry_weak
                                                            {
                                                                if let Some(registry) =
                                                                    registry_weak.upgrade()
                                                                {
                                                                    // Handle the actor message
                                                                    let actor_id_str =
                                                                        actor_id.to_string();
                                                                    match registry
                                                                        .handle_actor_message(
                                                                            &actor_id_str,
                                                                            type_hash,
                                                                            inner_payload,
                                                                            Some(correlation_id),
                                                                        )
                                                                        .await
                                                                    {
                                                                        Ok(Some(reply_payload)) => {
                                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, reply_len = reply_payload.len(),
                                                                           "Got reply from kameo actor, sending response back");

                                                                            // Create response message
                                                                            let mut response = bytes::BytesMut::with_capacity(4 + 8 + reply_payload.len());

                                                                            // Length prefix (4 bytes)
                                                                            let total_len = 8
                                                                                + reply_payload
                                                                                    .len()
                                                                                    as u32;
                                                                            response
                                                                                .extend_from_slice(
                                                                                &total_len
                                                                                    .to_be_bytes(),
                                                                            );

                                                                            // 8-byte header: msg_type(1) + correlation_id(2) + reserved(5)
                                                                            response.put_u8(crate::MessageType::Response as u8);
                                                                            response
                                                                                .extend_from_slice(
                                                                                &correlation_id
                                                                                    .to_be_bytes(),
                                                                            );
                                                                            response
                                                                                .extend_from_slice(
                                                                                    &[0u8; 5],
                                                                                );

                                                                            // Payload
                                                                            response
                                                                                .extend_from_slice(
                                                                                    &reply_payload,
                                                                                );

                                                                            // Send response back through the response handle we saved
                                                                            if let Some(
                                                                                ref handle,
                                                                            ) = response_handle
                                                                            {
                                                                                // We have the handle directly! Use it
                                                                                if let Err(e) = handle.write_bytes_nonblocking(response.freeze()) {
                                                                            warn!(peer = %peer_addr, error = %e, "Failed to send ask reply");
                                                                        } else {
                                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, "Sent ask reply directly through writer");
                                                                        }
                                                                            } else {
                                                                                // Fall back to finding in pool
                                                                                warn!(peer = %peer_addr, "No response_handle, falling back to pool lookup");
                                                                                let pool = registry
                                                                                    .connection_pool
                                                                                    .lock()
                                                                                    .await;
                                                                                if let Some(conn) = pool.connections.get(&peer_addr).map(|c| c.value().clone()) {
                                                                            if let Some(ref stream_handle) = conn.stream_handle {
                                                                                if let Err(e) = stream_handle.write_bytes_nonblocking(response.freeze()) {
                                                                                    warn!(peer = %peer_addr, error = %e, "Failed to send ask reply");
                                                                                } else {
                                                                                    debug!(peer = %peer_addr, correlation_id = correlation_id, "Sent ask reply through connection pool");
                                                                                }
                                                                            } else {
                                                                                warn!(peer = %peer_addr, "Connection has no stream handle");
                                                                            }
                                                                        } else {
                                                                            warn!(peer = %peer_addr, "No connection found in pool for reply");
                                                                        }
                                                                            }
                                                                        }
                                                                        Ok(None) => {
                                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, "No reply from kameo actor");
                                                                        }
                                                                        Err(e) => {
                                                                            warn!(peer = %peer_addr, error = %e, correlation_id = correlation_id, "Failed to handle kameo actor message");
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        } else {
                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, 
                                                               "Binary message payload too short: expected {} bytes but got {}", 
                                                               16 + payload_len, payload.len());
                                                        }
                                                    } else {
                                                        debug!(peer = %peer_addr, correlation_id = correlation_id, 
                                                           "Ask payload too short for binary format: {} bytes (need at least 16)", 
                                                           payload.len());
                                                    }
                                                }
                                            }
                                        }
                                    }
                                    crate::MessageType::Response => {
                                        // Handle incoming response
                                        if let Some(ref registry_weak) = registry_weak {
                                            if let Some(registry) = registry_weak.upgrade() {
                                                let pool = registry.connection_pool.lock().await;
                                                let mut delivered = false;

                                                // Look up peer ID for this address
                                                if let Some(peer_id) = pool
                                                    .addr_to_peer_id
                                                    .get(&peer_addr)
                                                    .map(|e| e.clone())
                                                {
                                                    // Use shared correlation tracker
                                                    if let Some(correlation) =
                                                        pool.correlation_trackers.get(&peer_id)
                                                    {
                                                        if correlation.has_pending(correlation_id) {
                                                            correlation.complete(
                                                                correlation_id,
                                                                payload.to_vec(),
                                                            );
                                                            debug!(peer = %peer_addr, correlation_id = correlation_id, "Delivered response to shared correlation tracker");
                                                            delivered = true;
                                                        }
                                                    }
                                                }

                                                if !delivered {
                                                    debug!(peer = %peer_addr, correlation_id = correlation_id, "Could not find pending request for correlation_id");
                                                }
                                            }
                                        }
                                    }
                                    crate::MessageType::Gossip => {
                                        // Gossip messages can arrive here, just ignore them
                                    }
                                    crate::MessageType::ActorTell => {
                                        // Direct actor tell message format:
                                        // Already parsed: [type:1][correlation_id:2][reserved:5]
                                        // Payload: [actor_id:8][type_hash:4][payload_len:4][payload:N]
                                        if payload.len() >= 16 {
                                            let actor_id = u64::from_be_bytes(
                                                payload[0..8].try_into().unwrap(),
                                            );
                                            let type_hash = u32::from_be_bytes(
                                                payload[8..12].try_into().unwrap(),
                                            );
                                            let payload_len = u32::from_be_bytes(
                                                payload[12..16].try_into().unwrap(),
                                            )
                                                as usize;

                                            if payload.len() >= 16 + payload_len {
                                                let actor_payload = &payload[16..16 + payload_len];

                                                // Log large ActorTell messages
                                                if payload_len > 1024 * 1024 {
                                                    info!(peer = %peer_addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash), 
                                                          payload_len = payload_len, "ðŸ“¨ LARGE ActorTell message - will call handler");
                                                }

                                                // Call actor message handler if available
                                                if let Some(ref registry_weak) = registry_weak {
                                                    if let Some(registry) = registry_weak.upgrade()
                                                    {
                                                        if let Some(ref handler) = &*registry
                                                            .actor_message_handler
                                                            .lock()
                                                            .await
                                                        {
                                                            if payload_len > 1024 * 1024 {
                                                                info!(peer = %peer_addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash),
                                                                       "ðŸš€ Calling actor message handler for LARGE ActorTell");
                                                            } else {
                                                                debug!(peer = %peer_addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash),
                                                                       "Calling actor message handler for ActorTell");
                                                            }
                                                            match handler
                                                                .handle_actor_message(
                                                                    &actor_id.to_string(),
                                                                    type_hash,
                                                                    actor_payload,
                                                                    None, // No correlation for tell
                                                                )
                                                                .await
                                                            {
                                                                Ok(_) => {
                                                                    if payload_len > 1024 * 1024 {
                                                                        info!(peer = %peer_addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash),
                                                                               "âœ… Successfully handled LARGE ActorTell");
                                                                    } else {
                                                                        debug!(peer = %peer_addr, actor_id = actor_id, type_hash = %format!("{:08x}", type_hash),
                                                                               "Successfully handled ActorTell");
                                                                    }
                                                                }
                                                                Err(e) => {
                                                                    error!(peer = %peer_addr, error = %e, "Failed to handle ActorTell on incoming connection")
                                                                }
                                                            }
                                                        } else {
                                                            warn!(peer = %peer_addr, "No actor message handler registered in registry");
                                                        }
                                                    } else {
                                                        warn!(peer = %peer_addr, "Registry weak reference could not be upgraded");
                                                    }
                                                } else {
                                                    warn!(peer = %peer_addr, "No registry weak reference available");
                                                }
                                            } else {
                                                warn!(peer = %peer_addr, expected = 16 + payload_len, actual = payload.len(), 
                                                      "ActorTell payload too short");
                                            }
                                        } else {
                                            warn!(peer = %peer_addr, payload_len = payload.len(), "ActorTell header too short");
                                        }
                                    }
                                    crate::MessageType::ActorAsk => {
                                        // TODO: Implement ActorAsk handling
                                        warn!(peer = %peer_addr, "ActorAsk not yet implemented");
                                    }
                                    crate::MessageType::StreamStart => {
                                        // Parse stream header from payload
                                        if payload.len() >= crate::StreamHeader::SERIALIZED_SIZE {
                                            if let Some(header) =
                                                crate::StreamHeader::from_bytes(&payload)
                                            {
                                                info!(peer = %peer_addr, stream_id = header.stream_id, total_size = header.total_size,
                                                      type_hash = %format!("{:08x}", header.type_hash), actor_id = header.actor_id,
                                                      "ðŸ“¥ StreamStart: Beginning streaming transfer");

                                                // Initialize stream assembly
                                                if let Some(ref registry_weak) = registry_weak {
                                                    if let Some(registry) = registry_weak.upgrade()
                                                    {
                                                        registry
                                                            .start_stream_assembly(header)
                                                            .await;
                                                    }
                                                }
                                            }
                                        }
                                    }
                                    crate::MessageType::StreamData => {
                                        // Parse stream header and data
                                        if payload.len() >= crate::StreamHeader::SERIALIZED_SIZE {
                                            if let Some(header) =
                                                crate::StreamHeader::from_bytes(&payload)
                                            {
                                                let data_start =
                                                    crate::StreamHeader::SERIALIZED_SIZE;
                                                if payload.len()
                                                    >= data_start + header.chunk_size as usize
                                                {
                                                    let chunk_data = &payload[data_start
                                                        ..data_start + header.chunk_size as usize];

                                                    // debug!(peer = %peer_addr, stream_id = header.stream_id, chunk_index = header.chunk_index,
                                                    //        chunk_size = header.chunk_size, "ðŸ“¦ StreamData: Received chunk");

                                                    // Add chunk to stream assembly
                                                    if let Some(ref registry_weak) = registry_weak {
                                                        if let Some(registry) =
                                                            registry_weak.upgrade()
                                                        {
                                                            registry
                                                                .add_stream_chunk(
                                                                    header,
                                                                    chunk_data.to_vec(),
                                                                )
                                                                .await;
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                    crate::MessageType::StreamEnd => {
                                        // Parse stream header and complete assembly
                                        if payload.len() >= crate::StreamHeader::SERIALIZED_SIZE {
                                            if let Some(header) =
                                                crate::StreamHeader::from_bytes(&payload)
                                            {
                                                info!(peer = %peer_addr, stream_id = header.stream_id,
                                                      "ðŸ“¤ StreamEnd: Completing streaming transfer");

                                                // Complete stream assembly and deliver to actor
                                                if let Some(ref registry_weak) = registry_weak {
                                                    if let Some(registry) = registry_weak.upgrade()
                                                    {
                                                        if let Some(complete_msg) = registry
                                                            .complete_stream_assembly(
                                                                header.stream_id,
                                                            )
                                                            .await
                                                        {
                                                            // Deliver to actor
                                                            if let Some(ref handler) = &*registry
                                                                .actor_message_handler
                                                                .lock()
                                                                .await
                                                            {
                                                                match handler
                                                                    .handle_actor_message(
                                                                        &header
                                                                            .actor_id
                                                                            .to_string(),
                                                                        header.type_hash,
                                                                        &complete_msg,
                                                                        None,
                                                                    )
                                                                    .await
                                                                {
                                                                    Ok(_) => {
                                                                        info!(peer = %peer_addr, stream_id = header.stream_id,
                                                                                  "âœ… Successfully delivered streamed message to actor")
                                                                    }
                                                                    Err(e) => {
                                                                        error!(peer = %peer_addr, stream_id = header.stream_id,
                                                                                    error = %e, "âŒ Failed to deliver streamed message")
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }

                                // if len > 1024 * 1024 {
                                //     eprintln!("ðŸ“¦ SERVER: Drained {} bytes from buffer after processing large message", total_len);
                                // }
                                partial_msg_buf.drain(..total_len);
                                continue;
                            }
                        }

                        // This is a gossip protocol message
                        let msg_data_vec = msg_data.to_vec();
                        partial_msg_buf.drain(..total_len);

                        // Add timing right after TCP read - BEFORE any deserialization
                        let tcp_read_timestamp = std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap()
                            .as_nanos();

                        // Process message
                        if let Some(ref registry_weak) = registry_weak {
                            if let Some(registry) = registry_weak.upgrade() {
                                if let Ok(msg) = rkyv::from_bytes::<
                                    crate::registry::RegistryMessage,
                                    rkyv::rancor::Error,
                                >(&msg_data_vec)
                                {
                                    // Debug: Show timing right after TCP read, before any processing
                                    match &msg {
                                        crate::registry::RegistryMessage::DeltaGossip { delta } => {
                                            let tcp_transmission_nanos = tcp_read_timestamp
                                                - delta.precise_timing_nanos as u128;
                                            let _tcp_transmission_ms =
                                                tcp_transmission_nanos as f64 / 1_000_000.0;
                                            // eprintln!("ðŸ” TCP_TRANSMISSION_TIME: {}ms ({}ns)", _tcp_transmission_ms, tcp_transmission_nanos);
                                        }
                                        _ => {}
                                    }

                                    if let Err(e) =
                                        handle_incoming_message(registry, peer_addr, msg).await
                                    {
                                        warn!(peer = %peer_addr, error = %e, "Failed to handle message");
                                    }
                                }
                            }
                        }
                    } else {
                        break;
                    }
                }
            }
            Err(e) => {
                warn!(peer = %peer_addr, error = %e, "Read error");
                break;
            }
        }
    }

    // Handle peer failure when connection is lost
    info!(peer = %peer_addr, "CONNECTION_POOL: Triggering peer failure handling");
    if let Some(ref registry_weak) = registry_weak {
        if let Some(registry) = registry_weak.upgrade() {
            if let Err(e) = registry.handle_peer_connection_failure(peer_addr).await {
                warn!(error = %e, peer = %peer_addr, "CONNECTION_POOL: Failed to handle peer connection failure");
            }
        }
    }
}

/// Implementation of persistent connection handling
async fn handle_persistent_connection_impl(
    stream: TcpStream,
    mut rx: mpsc::Receiver<Vec<u8>>,
    peer_addr: SocketAddr, // For outgoing: the peer's address. For incoming: the sender's listening address
    registry_weak: Option<std::sync::Weak<GossipRegistry>>,
) {
    use std::io;
    use tokio::io::{AsyncReadExt, AsyncWriteExt};

    info!(peer = %peer_addr, registry = ?registry_weak.is_some(), "persistent connection handler started");

    let (mut reader, mut writer) = stream.into_split();

    // Create a channel to signal EOF to write task
    let (eof_tx, mut eof_rx) = mpsc::channel::<()>(1);

    // Clone registry_weak for the read task
    let registry_weak_read = registry_weak.clone();

    // Spawn read task
    let read_task = tokio::spawn(async move {
        let mut partial_msg_buf = Vec::with_capacity(TCP_BUFFER_SIZE / 128); // Pre-allocate for common message sizes
        let mut read_buf = vec![0u8; TCP_BUFFER_SIZE / 128]; // Read buffer sized from master constant

        loop {
            match reader.read(&mut read_buf).await {
                Ok(0) => {
                    debug!(peer = %peer_addr, "ðŸ”´ CONNECTION POOL: Peer closed write (EOF) - half-closed");
                    // Signal EOF to write task
                    let _ = eof_tx.send(()).await;
                    return io::Result::Ok(());
                }
                Ok(n) => {
                    // Process the data we just read
                    partial_msg_buf.extend_from_slice(&read_buf[..n]);

                    // Try to process complete messages
                    while partial_msg_buf.len() >= 4 {
                        // All messages now have 4-byte length prefix
                        let len = u32::from_be_bytes([
                            partial_msg_buf[0],
                            partial_msg_buf[1],
                            partial_msg_buf[2],
                            partial_msg_buf[3],
                        ]) as usize;

                        if len > 100 * 1024 * 1024 {
                            warn!(peer = %peer_addr, "message too large: {}", len);
                            return Err(io::Error::new(
                                io::ErrorKind::InvalidData,
                                "message too large",
                            ));
                        }

                        let total_len = 4 + len;
                        if partial_msg_buf.len() >= total_len {
                            let msg_data = &partial_msg_buf[4..total_len];

                            // Check if this is an Ask/Response message by looking at first byte
                            if msg_data.len() >= 1 {
                                if let Some(msg_type) = crate::MessageType::from_byte(msg_data[0]) {
                                    // This is an Ask/Response message
                                    if msg_data.len() < 8 {
                                        warn!(peer = %peer_addr, "Ask/Response message too small");
                                        partial_msg_buf.drain(..total_len);
                                        continue;
                                    }

                                    let correlation_id =
                                        u16::from_be_bytes([msg_data[1], msg_data[2]]);
                                    let payload = &msg_data[8..];

                                    match msg_type {
                                        crate::MessageType::Ask => {
                                            // Handle incoming Ask requests for testing
                                            #[cfg(feature = "test-helpers")]
                                            {
                                                if let Some(ref registry_weak) = registry_weak_read
                                                {
                                                    if let Some(registry) = registry_weak.upgrade()
                                                    {
                                                        let conn = {
                                                            let pool = registry
                                                                .connection_pool
                                                                .lock()
                                                                .await;
                                                            pool.connections.get(&peer_addr).map(
                                                                |conn_ref| conn_ref.value().clone(),
                                                            )
                                                        };

                                                        if let Some(conn) = conn {
                                                            // Process the request and generate response
                                                            let request_str =
                                                                String::from_utf8_lossy(payload);
                                                            let response_data =
                                                                process_mock_request(&request_str);

                                                            // Build response message
                                                            let total_size =
                                                                8 + response_data.len();
                                                            let mut msg =
                                                                bytes::BytesMut::with_capacity(
                                                                    4 + total_size,
                                                                );

                                                            // Length prefix
                                                            msg.extend_from_slice(
                                                                &(total_size as u32).to_be_bytes(),
                                                            );

                                                            // Header: [type:1][corr_id:2][reserved:5]
                                                            msg.put_u8(
                                                                crate::MessageType::Response as u8,
                                                            );
                                                            msg.extend_from_slice(
                                                                &correlation_id.to_be_bytes(),
                                                            );
                                                            msg.extend_from_slice(&[0u8; 5]);
                                                            msg.extend_from_slice(&response_data);

                                                            // Send response back through stream handle
                                                            if let Some(ref stream_handle) =
                                                                conn.stream_handle
                                                            {
                                                                if let Err(e) = stream_handle
                                                                    .write_bytes_nonblocking(
                                                                        msg.freeze(),
                                                                    )
                                                                {
                                                                    warn!("Failed to send mock response: {}", e);
                                                                } else {
                                                                    debug!("Sent mock response for correlation_id {}", correlation_id);
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                            #[cfg(not(feature = "test-helpers"))]
                                            {
                                                warn!(peer = %peer_addr, correlation_id = correlation_id, "Received Ask request - not implemented in production");
                                            }
                                        }
                                        crate::MessageType::Response => {
                                            // Handle incoming response
                                            if let Some(ref registry_weak) = registry_weak_read {
                                                if let Some(registry) = registry_weak.upgrade() {
                                                    let pool =
                                                        registry.connection_pool.lock().await;
                                                    let mut delivered = false;

                                                    // Look up peer ID for this address
                                                    if let Some(peer_id) = pool
                                                        .addr_to_peer_id
                                                        .get(&peer_addr)
                                                        .map(|e| e.clone())
                                                    {
                                                        // Use shared correlation tracker
                                                        if let Some(correlation) =
                                                            pool.correlation_trackers.get(&peer_id)
                                                        {
                                                            if correlation
                                                                .has_pending(correlation_id)
                                                            {
                                                                correlation.complete(
                                                                    correlation_id,
                                                                    payload.to_vec(),
                                                                );
                                                                debug!(peer = %peer_addr, correlation_id = correlation_id, "Delivered response to shared correlation tracker");
                                                                delivered = true;
                                                            }
                                                        }
                                                    }

                                                    if !delivered {
                                                        debug!(peer = %peer_addr, correlation_id = correlation_id, "Could not find pending request for correlation_id");
                                                    }
                                                }
                                            }
                                        }
                                        crate::MessageType::Gossip => {
                                            // Gossip messages can arrive here, just ignore them
                                        }
                                        crate::MessageType::ActorTell
                                        | crate::MessageType::ActorAsk => {
                                            // These can arrive here too, just process them normally
                                        }
                                        crate::MessageType::StreamStart
                                        | crate::MessageType::StreamData
                                        | crate::MessageType::StreamEnd => {
                                            // Streaming messages processed above
                                        }
                                    }

                                    partial_msg_buf.drain(..total_len);
                                    continue;
                                }
                            }

                            // This is a gossip protocol message
                            match rkyv::from_bytes::<RegistryMessage, rkyv::rancor::Error>(msg_data)
                            {
                                Ok(msg) => {
                                    if let Some(ref registry_weak) = registry_weak_read {
                                        if let Some(registry) = registry_weak.upgrade() {
                                            // Direct inline processing for minimum latency
                                            if let Err(e) =
                                                handle_incoming_message(registry, peer_addr, msg)
                                                    .await
                                            {
                                                warn!(peer = %peer_addr, error = %e, "failed to handle incoming message");
                                            }
                                        }
                                    }
                                }
                                Err(e) => {
                                    warn!(peer = %peer_addr, error = %e, "failed to deserialize message");
                                }
                            }

                            // Remove processed message from buffer AFTER processing
                            partial_msg_buf.drain(..total_len);
                        } else {
                            // Need more data for complete message
                            break;
                        }
                    }
                }
                Err(ref e) if e.kind() == io::ErrorKind::Interrupted => continue,
                Err(e) => {
                    warn!(peer = %peer_addr, error = %e, "error reading from socket");
                    return Err(e);
                }
            }
        }
    });

    // Spawn write task
    let write_task = tokio::spawn(async move {
        loop {
            tokio::select! {
                // Check for EOF signal
                _ = eof_rx.recv() => {
                    debug!(peer = %peer_addr, "ðŸ”´ CONNECTION POOL: EOF signal received, shutting down write task");
                    return io::Result::Ok(());
                }
                // Check for messages to send
                msg = rx.recv() => {
                    match msg {
                        Some(data) => {
                            match writer.write_all(&data).await {
                                Ok(_) => {
                                    // CRITICAL: Flush immediately to avoid TCP buffering delays
                                    if let Err(e) = writer.flush().await {
                                        warn!(peer = %peer_addr, error = %e, "failed to flush TCP socket");
                                        return Err(e);
                                    }
                                    debug!(peer = %peer_addr, bytes = data.len(), "ðŸ“¤ CONNECTION POOL: Sent and flushed message");
                                }
                                Err(ref e) if e.kind() == io::ErrorKind::BrokenPipe
                                          || e.kind() == io::ErrorKind::ConnectionReset => {
                                    debug!(peer = %peer_addr, "ðŸ”´ CONNECTION POOL: Peer closed read - write failed");
                                    return io::Result::Ok(());
                                }
                                Err(e) => {
                                    warn!(peer = %peer_addr, error = %e, "failed to write");
                                    return Err(e);
                                }
                            }
                        }
                        None => {
                            debug!(peer = %peer_addr, "ðŸ”´ CONNECTION POOL: channel closed, shutting down write task");
                            return io::Result::Ok(());
                        }
                    }
                }
            }
        }
    });

    // Wait for both tasks to complete
    let (read_res, write_res) = tokio::join!(read_task, write_task);

    // Log results
    match read_res {
        Ok(Ok(_)) => info!(peer = %peer_addr, "read task completed successfully"),
        Ok(Err(e)) => warn!(peer = %peer_addr, error = %e, "read task failed"),
        Err(e) => warn!(peer = %peer_addr, error = %e, "read task panicked"),
    }

    match write_res {
        Ok(Ok(_)) => info!(peer = %peer_addr, "write task completed successfully"),
        Ok(Err(e)) => warn!(peer = %peer_addr, error = %e, "write task failed"),
        Err(e) => warn!(peer = %peer_addr, error = %e, "write task panicked"),
    }

    // Notify of disconnection
    info!(peer = %peer_addr, "persistent connection lost, triggering failure handling");

    // Mark connection as disconnected in the pool
    if let Some(ref registry_weak) = registry_weak {
        if let Some(registry) = registry_weak.upgrade() {
            // First mark disconnected in pool
            {
                let mut pool = registry.connection_pool.lock().await;
                pool.mark_disconnected(peer_addr);
            }

            // Then handle the failure in a separate task
            let failed_addr = peer_addr;
            tokio::spawn(async move {
                if let Err(e) = registry.handle_peer_connection_failure(failed_addr).await {
                    warn!(error = %e, peer = %failed_addr, "failed to handle peer connection failure");
                }
            });
        }
    }
}

/// Handle an incoming message on a bidirectional connection
pub(crate) async fn handle_incoming_message(
    registry: Arc<GossipRegistry>,
    _peer_addr: SocketAddr,
    msg: RegistryMessage,
) -> Result<()> {
    match msg {
        RegistryMessage::DeltaGossip { delta } => {
            debug!(
                sender = %delta.sender_peer_id,
                since_sequence = delta.since_sequence,
                changes = delta.changes.len(),
                "received delta gossip message on bidirectional connection"
            );

            // OPTIMIZATION: Do all peer management in one lock acquisition
            {
                let mut gossip_state = registry.gossip_state.lock().await;

                // Use the actual peer address we received from
                let sender_socket_addr = _peer_addr;

                // Add the sender as a peer (inlined to avoid separate lock)
                if delta.sender_peer_id != registry.peer_id {
                    if let std::collections::hash_map::Entry::Vacant(e) =
                        gossip_state.peers.entry(sender_socket_addr)
                    {
                        let current_time = crate::current_timestamp();
                        e.insert(crate::registry::PeerInfo {
                            address: sender_socket_addr,
                            peer_address: None,
                            node_id: None,
                            failures: 0,
                            last_attempt: current_time,
                            last_success: current_time,
                            last_sequence: 0,
                            last_sent_sequence: 0,
                            consecutive_deltas: 0,
                            last_failure_time: None,
                        });
                    }
                }

                // Check if this is a previously failed peer
                let was_failed = gossip_state
                    .peers
                    .get(&sender_socket_addr)
                    .map(|info| info.failures >= registry.config.max_peer_failures)
                    .unwrap_or(false);

                if was_failed {
                    info!(
                        peer = %delta.sender_peer_id,
                        "âœ… Received delta from previously failed peer - connection restored!"
                    );

                    // Clear the pending failure record
                    gossip_state
                        .pending_peer_failures
                        .remove(&sender_socket_addr);
                }

                // Update peer info and check if we need to clear pending failures
                let need_to_clear_pending =
                    if let Some(peer_info) = gossip_state.peers.get_mut(&sender_socket_addr) {
                        // Always reset failure state when we receive messages from the peer
                        // This proves the peer is alive and communicating
                        let had_failures = peer_info.failures > 0;
                        if had_failures {
                            info!(peer = %delta.sender_peer_id, 
                              prev_failures = peer_info.failures,
                              "ðŸ”„ Resetting failure state after receiving DeltaGossip");
                            peer_info.failures = 0;
                            peer_info.last_failure_time = None;
                        }
                        peer_info.last_success = crate::current_timestamp();

                        peer_info.last_sequence =
                            std::cmp::max(peer_info.last_sequence, delta.current_sequence);
                        peer_info.consecutive_deltas += 1;

                        had_failures
                    } else {
                        false
                    };

                // Clear pending failure record if needed
                if need_to_clear_pending {
                    gossip_state
                        .pending_peer_failures
                        .remove(&sender_socket_addr);
                }
                gossip_state.delta_exchanges += 1;
            }

            // CRITICAL OPTIMIZATION: Inline apply_delta to eliminate function call overhead
            // Apply the delta directly here to minimize async scheduling delays
            {
                let total_changes = delta.changes.len();
                // Use the actual peer address we received from
                let sender_addr = _peer_addr;

                // Pre-compute priority flags to avoid redundant checks
                let has_immediate = delta.changes.iter().any(|change| match change {
                    crate::registry::RegistryChange::ActorAdded { priority, .. } => {
                        priority.should_trigger_immediate_gossip()
                    }
                    crate::registry::RegistryChange::ActorRemoved { priority, .. } => {
                        priority.should_trigger_immediate_gossip()
                    }
                });

                if has_immediate {
                    info!(
                        "ðŸŽ¯ RECEIVING IMMEDIATE CHANGES: {} total changes from {}",
                        total_changes, sender_addr
                    );
                }

                // Pre-capture timing info outside lock for better performance - use high resolution timing
                let _received_instant = std::time::Instant::now();
                let received_timestamp = std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_nanos();

                // eprintln!("ðŸ” RECEIVED_TIMESTAMP: {}ns", received_timestamp);

                // Collect immediate actors for ACK before consuming changes
                let mut immediate_actors = Vec::new();
                for change in &delta.changes {
                    if let crate::registry::RegistryChange::ActorAdded { name, priority, .. } =
                        change
                    {
                        if priority.should_trigger_immediate_gossip() {
                            immediate_actors.push(name.clone());
                        }
                    }
                }

                // OPTIMIZATION: Fast-path state updates with try_lock to avoid blocking
                let (applied_count, _pending_updates) = {
                    // Try non-blocking access first
                    if let Ok(mut actor_state) = registry.actor_state.try_write() {
                        // Fast path - direct update without batching overhead
                        let mut applied = 0;
                        for change in delta.changes {
                            match change {
                                crate::registry::RegistryChange::ActorAdded {
                                    name,
                                    location,
                                    priority: _,
                                } => {
                                    // Don't override local actors
                                    if actor_state.local_actors.contains_key(name.as_str()) {
                                        continue;
                                    }

                                    // Quick conflict check
                                    let should_apply =
                                        match actor_state.known_actors.get(name.as_str()) {
                                            Some(existing) => {
                                                location.wall_clock_time > existing.wall_clock_time
                                                    || (location.wall_clock_time
                                                        == existing.wall_clock_time
                                                        && location.address > existing.address)
                                            }
                                            None => true,
                                        };

                                    if should_apply {
                                        actor_state
                                            .known_actors
                                            .insert(name.clone(), location.clone());
                                        applied += 1;

                                        // Inline timing calculation for immediate priority
                                        if location.priority.should_trigger_immediate_gossip() {
                                            let network_time_nanos = received_timestamp
                                                - delta.precise_timing_nanos as u128;
                                            let network_time_ms =
                                                network_time_nanos as f64 / 1_000_000.0;
                                            let propagation_time_ms = network_time_ms; // Same as network time for now
                                            let processing_only_time_ms = 0.0; // No additional processing time beyond network

                                            eprintln!("ðŸ” FAST_PATH: Processing immediate priority actor: {} propagation_time_ms={:.3}ms", name, propagation_time_ms);

                                            info!(
                                                actor_name = %name,
                                                priority = ?location.priority,
                                                propagation_time_ms = propagation_time_ms,
                                                network_processing_time_ms = network_time_ms,
                                                processing_only_time_ms = processing_only_time_ms,
                                                "RECEIVED_ACTOR"
                                            );
                                        }
                                    }
                                }
                                crate::registry::RegistryChange::ActorRemoved {
                                    name,
                                    vector_clock,
                                    removing_node_id,
                                    priority: _,
                                } => {
                                    // Check vector clock ordering before applying removal
                                    let should_remove =
                                        match actor_state.known_actors.get(name.as_str()) {
                                            Some(existing_location) => {
                                                match vector_clock
                                                    .compare(&existing_location.vector_clock)
                                                {
                                                    crate::ClockOrdering::After => true,
                                                    crate::ClockOrdering::Concurrent => {
                                                        // For concurrent removals, use node_id as deterministic tiebreaker
                                                        // This ensures all nodes make the same decision
                                                        removing_node_id > existing_location.node_id
                                                    }
                                                    _ => false, // Ignore outdated removals (Before or Equal)
                                                }
                                            }
                                            None => false, // Actor doesn't exist
                                        };

                                    if should_remove
                                        && actor_state.known_actors.remove(name.as_str()).is_some()
                                    {
                                        applied += 1;
                                    }
                                }
                            }
                        }
                        (applied, Vec::new())
                    } else {
                        // Fallback to batched approach if lock is contended
                        let actor_state = registry.actor_state.read().await;
                        let mut pending_updates = Vec::new();
                        let mut pending_removals = Vec::new();

                        for change in &delta.changes {
                            match change {
                                crate::registry::RegistryChange::ActorAdded {
                                    name,
                                    location,
                                    priority: _,
                                } => {
                                    // Don't override local actors - early exit
                                    if actor_state.local_actors.contains_key(name.as_str()) {
                                        debug!(
                                            actor_name = %name,
                                            "skipping remote actor update - actor is local"
                                        );
                                        continue;
                                    }

                                    // Check if we already know about this actor
                                    let should_apply =
                                        match actor_state.known_actors.get(name.as_str()) {
                                            Some(existing_location) => {
                                                // Use vector clock for causal ordering
                                                match location
                                                    .vector_clock
                                                    .compare(&existing_location.vector_clock)
                                                {
                                                    crate::ClockOrdering::After => true,
                                                    crate::ClockOrdering::Concurrent => {
                                                        // For concurrent updates, use node_id as tiebreaker
                                                        location.node_id > existing_location.node_id
                                                    }
                                                    _ => false, // Keep existing for Before or Equal
                                                }
                                            }
                                            None => {
                                                debug!(
                                                    actor_name = %name,
                                                    "applying new actor"
                                                );
                                                true // New actor
                                            }
                                        };

                                    if should_apply {
                                        pending_updates.push((name.clone(), location.clone()));
                                    }
                                }
                                crate::registry::RegistryChange::ActorRemoved {
                                    name,
                                    vector_clock,
                                    removing_node_id,
                                    priority: _,
                                } => {
                                    // Check vector clock ordering before queueing removal
                                    if let Some(existing_location) =
                                        actor_state.known_actors.get(name.as_str())
                                    {
                                        match vector_clock.compare(&existing_location.vector_clock)
                                        {
                                            crate::ClockOrdering::After => {
                                                // Queue removal if it's after
                                                pending_removals.push((
                                                    name.clone(),
                                                    vector_clock.clone(),
                                                    *removing_node_id,
                                                ));
                                            }
                                            crate::ClockOrdering::Concurrent => {
                                                // For concurrent removals, use node_id as tiebreaker
                                                if removing_node_id > &existing_location.node_id {
                                                    pending_removals.push((
                                                        name.clone(),
                                                        vector_clock.clone(),
                                                        *removing_node_id,
                                                    ));
                                                }
                                            }
                                            _ => {} // Ignore outdated removals (Before or Equal)
                                        }
                                    }
                                }
                            }
                        }

                        // Drop read lock before acquiring write lock
                        drop(actor_state);

                        // Second pass: apply all updates under write lock with re-validation
                        let mut actor_state = registry.actor_state.write().await;
                        let mut applied = 0;

                        // Re-validate and apply actor additions
                        for (name, location) in &pending_updates {
                            // Re-check if this is still valid (state may have changed)
                            let still_valid = match actor_state.known_actors.get(name.as_str()) {
                                Some(existing_location) => {
                                    match location
                                        .vector_clock
                                        .compare(&existing_location.vector_clock)
                                    {
                                        crate::ClockOrdering::After => true,
                                        crate::ClockOrdering::Concurrent => {
                                            location.node_id > existing_location.node_id
                                        }
                                        _ => false,
                                    }
                                }
                                None => !actor_state.local_actors.contains_key(name.as_str()),
                            };

                            if still_valid {
                                actor_state
                                    .known_actors
                                    .insert(name.clone(), location.clone());
                                applied += 1;

                                // Log the timing information for immediate priority changes
                                if location.priority.should_trigger_immediate_gossip() {
                                    // Calculate time from when delta was sent (network + processing)
                                    let network_processing_time_nanos =
                                        received_timestamp - delta.precise_timing_nanos as u128;
                                    let network_processing_time_ms =
                                        network_processing_time_nanos as f64 / 1_000_000.0;
                                    let propagation_time_ms = network_processing_time_ms; // Same as network time for now
                                    let processing_only_time_ms = 0.0; // No additional processing time beyond network

                                    // Debug: Break down where the time is spent
                                    eprintln!("ðŸ” TIMING_BREAKDOWN: sent={}, received={}, delta={}ns ({}ms)", 
                                     delta.precise_timing_nanos, received_timestamp, 
                                     network_processing_time_nanos, network_processing_time_ms);

                                    info!(
                                        actor_name = %name,
                                        priority = ?location.priority,
                                        propagation_time_ms = propagation_time_ms,
                                        network_processing_time_ms = network_processing_time_ms,
                                        processing_only_time_ms = processing_only_time_ms,
                                        "RECEIVED_ACTOR"
                                    );
                                }
                            }
                        }

                        // Re-validate and apply actor removals
                        for (name, removal_clock, removing_node_id) in &pending_removals {
                            // Re-check if removal is still valid (state may have changed)
                            if let Some(existing_location) =
                                actor_state.known_actors.get(name.as_str())
                            {
                                let still_valid =
                                    match removal_clock.compare(&existing_location.vector_clock) {
                                        crate::ClockOrdering::After => true,
                                        crate::ClockOrdering::Concurrent => {
                                            // Use same deterministic tiebreaker for re-validation
                                            removing_node_id > &existing_location.node_id
                                        }
                                        _ => false,
                                    };

                                if still_valid
                                    && actor_state.known_actors.remove(name.as_str()).is_some()
                                {
                                    applied += 1;
                                }
                            }
                        }

                        (applied, pending_updates)
                    }
                };

                if applied_count > 0 {
                    debug!(
                        applied_count = applied_count,
                        sender = %sender_addr,
                        "applied delta changes in batched update"
                    );
                }

                // NEW: Send ACK back for immediate registrations
                if !immediate_actors.is_empty() {
                    // Send ACKs for immediate priority actor additions
                    // Use lock-free send since we're responding on the same connection
                    let pool = registry.connection_pool.lock().await;
                    for actor_name in immediate_actors {
                        // Send lightweight ACK immediately
                        let ack = crate::registry::RegistryMessage::ImmediateAck {
                            actor_name: actor_name.clone(),
                            success: true,
                        };

                        // Serialize and send
                        if let Ok(serialized) = rkyv::to_bytes::<rkyv::rancor::Error>(&ack) {
                            // Use send_lock_free to send directly without needing a connection handle
                            if let Err(e) = pool.send_lock_free(_peer_addr, &serialized) {
                                warn!("Failed to send ImmediateAck: {}", e);
                            } else {
                                info!("Sent ImmediateAck for actor '{}'", actor_name);
                            }
                        }
                    }
                }
            }

            // Note: Response will be sent during regular gossip rounds
            Ok(())
        }
        RegistryMessage::FullSync {
            local_actors,
            known_actors,
            sender_peer_id,
            sequence,
            wall_clock_time,
        } => {
            // We no longer have sender address - will need to handle differently
            let sender_socket_addr = _peer_addr; // Use the actual peer address

            // Note: sender_peer_id is now a PeerId (e.g., "node_a"), not an address
            debug!(
                "Received FullSync from node '{}' at address {}",
                sender_peer_id, sender_socket_addr
            );

            // OPTIMIZATION: Do all peer management in one lock acquisition
            {
                let mut gossip_state = registry.gossip_state.lock().await;

                // Add the sender as a peer (inlined to avoid separate lock)
                if sender_socket_addr != registry.bind_addr {
                    if let std::collections::hash_map::Entry::Vacant(e) =
                        gossip_state.peers.entry(sender_socket_addr)
                    {
                        info!(peer = %sender_socket_addr, "Adding new peer from FullSync");
                        let current_time = crate::current_timestamp();
                        e.insert(crate::registry::PeerInfo {
                            address: sender_socket_addr,
                            peer_address: None,
                            node_id: None,
                            failures: 0,
                            last_attempt: current_time,
                            last_success: current_time,
                            last_sequence: 0,
                            last_sent_sequence: 0,
                            consecutive_deltas: 0,
                            last_failure_time: None,
                        });
                    }
                }

                // Update peer info and reset failure state
                let had_failures = gossip_state
                    .peers
                    .get(&sender_socket_addr)
                    .map(|info| info.failures > 0)
                    .unwrap_or(false);

                if had_failures {
                    // Clear the pending failure record
                    gossip_state
                        .pending_peer_failures
                        .remove(&sender_socket_addr);
                }

                if let Some(peer_info) = gossip_state.peers.get_mut(&sender_socket_addr) {
                    let prev_failures = peer_info.failures;
                    // Always reset failure state when we receive a FullSync from the peer
                    // This proves the peer is alive and communicating
                    if peer_info.failures > 0 {
                        info!(peer = %sender_socket_addr, 
                              prev_failures = prev_failures,
                              "ðŸ”„ Resetting failure state after receiving FullSync");
                        peer_info.failures = 0;
                        peer_info.last_failure_time = None;
                    }
                    peer_info.last_success = crate::current_timestamp();
                    peer_info.consecutive_deltas = 0;
                } else {
                    warn!(peer = %sender_socket_addr, "Peer not found in peer list when trying to reset failure state");
                }
                gossip_state.full_sync_exchanges += 1;
            }

            debug!(
                sender = %sender_peer_id,
                sequence = sequence,
                local_actors = local_actors.len(),
                known_actors = known_actors.len(),
                "ðŸ“¨ INCOMING: Received full sync message on bidirectional connection"
            );

            // IMPORTANT: Register the incoming connection with the peer_id mapping
            // This allows bidirectional communication to work properly
            {
                let pool = registry.connection_pool.lock().await;
                pool.peer_id_to_addr
                    .insert(sender_peer_id.clone(), sender_socket_addr);
                pool.addr_to_peer_id
                    .insert(sender_socket_addr, sender_peer_id.clone());
                debug!(
                    "BIDIRECTIONAL: Registered incoming connection - peer_id={} addr={}",
                    sender_peer_id, sender_socket_addr
                );
            }

            // Only remaining async operation
            registry
                .merge_full_sync(
                    local_actors.into_iter().collect(),
                    known_actors.into_iter().collect(),
                    sender_socket_addr,
                    sequence,
                    wall_clock_time,
                )
                .await;

            // Send back our state as a response so the sender can receive our actors
            // This is critical for late-joining nodes (like Node C) to get existing state
            {
                // Get our current state
                let (our_local_actors, our_known_actors, our_sequence) = {
                    let actor_state = registry.actor_state.read().await;
                    let gossip_state = registry.gossip_state.lock().await;
                    (
                        actor_state.local_actors.clone(),
                        actor_state.known_actors.clone(),
                        gossip_state.gossip_sequence,
                    )
                };

                // Calculate sizes before moving
                let local_actors_count = our_local_actors.len();
                let known_actors_count = our_known_actors.len();

                // Create a FullSyncResponse message
                let response = RegistryMessage::FullSyncResponse {
                    local_actors: our_local_actors.into_iter().map(|(k, v)| (k, v)).collect(),
                    known_actors: our_known_actors.into_iter().map(|(k, v)| (k, v)).collect(),
                    sender_peer_id: registry.peer_id.clone(), // Use peer ID
                    sequence: our_sequence,
                    wall_clock_time: crate::current_timestamp(),
                };

                // Send the response back through existing connection
                // We'll use send_lock_free which doesn't create new connections
                let response_data = match rkyv::to_bytes::<rkyv::rancor::Error>(&response) {
                    Ok(data) => data,
                    Err(e) => {
                        warn!(error = %e, "Failed to serialize FullSync response");
                        return Ok(());
                    }
                };

                // Try to send immediately on existing connection
                {
                    debug!(
                        "FULLSYNC RESPONSE: Node {} is about to acquire connection pool lock",
                        registry.bind_addr
                    );
                    let pool = registry.connection_pool.lock().await;
                    debug!(
                        "FULLSYNC RESPONSE: Node {} got pool lock, pool has {} total entries",
                        registry.bind_addr,
                        pool.connection_count()
                    );
                    debug!("FULLSYNC RESPONSE: Pool instance address: {:p}", &*pool);

                    // Log details about each connection
                    for entry in pool.connections.iter() {
                        let addr = entry.key();
                        let conn = entry.value();
                        debug!(
                            "FULLSYNC RESPONSE: Connection to {} - state={:?}",
                            addr,
                            conn.get_state()
                        );
                    }

                    // Create message with length prefix
                    let mut buffer = bytes::BytesMut::with_capacity(4 + response_data.len());
                    buffer.extend_from_slice(&(response_data.len() as u32).to_be_bytes());
                    buffer.extend_from_slice(&response_data);

                    // Debug: Log what connections we have
                    debug!(
                        "FULLSYNC RESPONSE DEBUG: Available connections by addr: {:?}",
                        pool.connections
                            .iter()
                            .map(|entry| entry.key().clone())
                            .collect::<Vec<_>>()
                    );
                    debug!(
                        "FULLSYNC RESPONSE DEBUG: Available node mappings: {:?}",
                        pool.peer_id_to_addr
                            .iter()
                            .map(|entry| (entry.key().clone(), entry.value().clone()))
                            .collect::<Vec<_>>()
                    );
                    debug!(
                        "FULLSYNC RESPONSE DEBUG: Looking for connection to sender_peer_id: {}",
                        sender_peer_id
                    );
                    debug!(
                        "FULLSYNC RESPONSE DEBUG: sender_socket_addr={}",
                        sender_socket_addr
                    );

                    // Try to send using peer ID
                    let frozen_buffer = buffer.freeze();
                    let send_result = match pool
                        .send_bytes_to_node_id(&sender_peer_id.as_str(), frozen_buffer.clone())
                    {
                        Ok(()) => Ok(()),
                        Err(e) => {
                            warn!("Failed to send via peer ID {}: {}", sender_peer_id, e);
                            // Fall back to socket address
                            pool.send_lock_free(sender_socket_addr, &frozen_buffer)
                        }
                    };

                    if send_result.is_err() {
                        warn!(
                            "Primary send failed for peer {}, no fallback available",
                            sender_peer_id
                        );
                    }

                    match send_result {
                        Ok(()) => {
                            debug!(peer = %sender_socket_addr, 
                                  peer_id = %sender_peer_id,
                                  local_actors = local_actors_count,
                                  known_actors = known_actors_count,
                                  bind_addr = %registry.bind_addr,
                                  "ðŸ“¤ RESPONSE: Successfully sent FullSync response with our state");
                        }
                        Err(e) => {
                            // If we can't send immediately, queue it for the next gossip round
                            warn!(peer = %sender_socket_addr, 
                                  peer_id = %sender_peer_id,
                                  error = %e, 
                                  "Could not send FullSync response immediately - will be sent in next gossip round");

                            // Store in gossip state to be sent during next gossip round
                            drop(pool); // Release the pool lock first
                            let mut gossip_state = registry.gossip_state.lock().await;

                            // Mark that we need to send a full sync to this peer
                            if let Some(peer_info) = gossip_state.peers.get_mut(&sender_socket_addr)
                            {
                                // Force a full sync on the next gossip round
                                peer_info.consecutive_deltas =
                                    registry.config.max_delta_history as u64;
                                info!(peer = %sender_socket_addr, 
                                      "Marked peer for full sync in next gossip round");
                            }
                        }
                    }
                }
            }

            Ok(())
        }
        RegistryMessage::FullSyncRequest {
            sender_peer_id,
            sequence: _,
            wall_clock_time: _,
        } => {
            debug!(
                sender = %sender_peer_id,
                "received full sync request on bidirectional connection"
            );

            {
                let mut gossip_state = registry.gossip_state.lock().await;
                gossip_state.full_sync_exchanges += 1;
            }

            // Note: Response will be sent during regular gossip rounds
            Ok(())
        }
        // Handle response messages (these can arrive on incoming connections too)
        RegistryMessage::DeltaGossipResponse { delta } => {
            debug!(
                sender = %delta.sender_peer_id,
                changes = delta.changes.len(),
                "received delta gossip response on bidirectional connection"
            );

            if let Err(err) = registry.apply_delta(delta).await {
                warn!(error = %err, "failed to apply delta from response");
            } else {
                let mut gossip_state = registry.gossip_state.lock().await;
                gossip_state.delta_exchanges += 1;
            }
            Ok(())
        }
        RegistryMessage::FullSyncResponse {
            local_actors,
            known_actors,
            sender_peer_id,
            sequence,
            wall_clock_time,
        } => {
            debug!(
                sender = %sender_peer_id,
                local_actors = local_actors.len(),
                known_actors = known_actors.len(),
                "RECEIVED: FullSyncResponse from peer"
            );

            // Use the actual peer address we're connected to
            let sender_socket_addr = _peer_addr;

            registry
                .merge_full_sync(
                    local_actors.into_iter().collect(),
                    known_actors.into_iter().collect(),
                    sender_socket_addr,
                    sequence,
                    wall_clock_time,
                )
                .await;

            // Reset failure state when receiving response
            let mut gossip_state = registry.gossip_state.lock().await;

            // Reset failure state for responding peer
            let need_to_clear_pending =
                if let Some(peer_info) = gossip_state.peers.get_mut(&sender_socket_addr) {
                    let had_failures = peer_info.failures > 0;
                    if had_failures {
                        info!(peer = %sender_socket_addr, 
                          prev_failures = peer_info.failures,
                          "ðŸ”„ Resetting failure state after receiving FullSyncResponse");
                        peer_info.failures = 0;
                        peer_info.last_failure_time = None;
                    }
                    peer_info.last_success = crate::current_timestamp();
                    had_failures
                } else {
                    false
                };

            // Clear pending failure record if needed
            if need_to_clear_pending {
                gossip_state
                    .pending_peer_failures
                    .remove(&sender_socket_addr);
            }

            gossip_state.full_sync_exchanges += 1;
            Ok(())
        }
        RegistryMessage::PeerHealthQuery {
            sender,
            target_peer,
            timestamp: _,
        } => {
            debug!(
                sender = %sender,
                target = %target_peer,
                "received peer health query"
            );

            // Check our connection status to the target peer
            let target_addr = match target_peer.parse::<SocketAddr>() {
                Ok(addr) => addr,
                Err(_) => {
                    warn!(
                        "Invalid target peer address in health query: {}",
                        target_peer
                    );
                    return Ok(());
                }
            };

            let is_alive = {
                let pool = registry.connection_pool.lock().await;
                pool.has_connection(&target_addr)
            };

            let last_contact = if is_alive {
                crate::current_timestamp()
            } else {
                // Check when we last had successful contact
                let gossip_state = registry.gossip_state.lock().await;
                gossip_state
                    .peers
                    .get(&target_addr)
                    .map(|info| info.last_success)
                    .unwrap_or(0)
            };

            // Send our health report back
            let mut peer_statuses = HashMap::new();

            // Get actual failure count from gossip state
            let failure_count = {
                let gossip_state = registry.gossip_state.lock().await;
                gossip_state
                    .peers
                    .get(&target_addr)
                    .map(|info| info.failures as u32)
                    .unwrap_or(0)
            };

            peer_statuses.insert(
                target_peer,
                crate::registry::PeerHealthStatus {
                    is_alive,
                    last_contact,
                    failure_count,
                },
            );

            let report = RegistryMessage::PeerHealthReport {
                reporter: registry.peer_id.clone(),
                peer_statuses: peer_statuses.into_iter().collect(),
                timestamp: crate::current_timestamp(),
            };

            // Send report back to the querying peer
            if let Ok(data) = rkyv::to_bytes::<rkyv::rancor::Error>(&report) {
                let pool = registry.connection_pool.lock().await;
                // Use the actual peer address we received from
                let sender_addr = _peer_addr;

                // Create message with length prefix
                let mut buffer = bytes::BytesMut::with_capacity(4 + data.len());
                buffer.extend_from_slice(&(data.len() as u32).to_be_bytes());
                buffer.extend_from_slice(&data);

                // Use send_lock_free which doesn't create new connections
                if let Err(e) = pool.send_lock_free(sender_addr, &buffer.freeze()) {
                    warn!(peer = %sender_addr, error = %e, "Failed to send peer health report");
                }
            }

            Ok(())
        }
        RegistryMessage::PeerHealthReport {
            reporter,
            peer_statuses,
            timestamp: _,
        } => {
            debug!(
                reporter = %reporter,
                peers = peer_statuses.len(),
                "received peer health report"
            );

            // Store the health reports
            {
                let mut gossip_state = registry.gossip_state.lock().await;
                for (peer, status) in peer_statuses {
                    if let Ok(peer_addr) = peer.parse::<SocketAddr>() {
                        // For now, use the reporter's peer address from the connection
                        gossip_state
                            .peer_health_reports
                            .entry(peer_addr)
                            .or_insert_with(HashMap::new)
                            .insert(_peer_addr, status);
                    }
                }
            }

            // Check if we have enough reports to make a decision
            registry.check_peer_consensus().await;

            Ok(())
        }
        RegistryMessage::ActorMessage {
            actor_id,
            type_hash,
            payload,
            correlation_id,
        } => {
            debug!(
                actor_id = %actor_id,
                type_hash = %format!("{:08x}", type_hash),
                payload_len = payload.len(),
                correlation_id = ?correlation_id,
                "received actor message"
            );

            // Forward to the registry's actor message handler
            match registry
                .handle_actor_message(&actor_id, type_hash, &payload, correlation_id)
                .await
            {
                Ok(Some(reply_payload)) => {
                    // If there's a correlation_id, this is an ask message and we need to send the reply back
                    if let Some(corr_id) = correlation_id {
                        debug!(
                            actor_id = %actor_id,
                            type_hash = %format!("{:08x}", type_hash),
                            correlation_id = corr_id,
                            reply_len = reply_payload.len(),
                            "sending ask reply back to sender"
                        );

                        // Create response message with the correlation_id
                        let mut response =
                            bytes::BytesMut::with_capacity(4 + 8 + reply_payload.len());

                        // Length prefix (4 bytes)
                        let total_len = 8 + reply_payload.len() as u32;
                        response.extend_from_slice(&total_len.to_be_bytes());

                        // 8-byte header: msg_type(1) + correlation_id(2) + reserved(5)
                        response.put_u8(crate::MessageType::Response as u8); // 0x02 for Response
                        response.extend_from_slice(&corr_id.to_be_bytes());
                        response.extend_from_slice(&[0u8; 5]); // reserved bytes

                        // Payload
                        response.extend_from_slice(&reply_payload);

                        // Send response back through the same connection
                        let pool = registry.connection_pool.lock().await;
                        if let Err(e) = pool.send_lock_free(_peer_addr, &response.freeze()) {
                            warn!(peer = %_peer_addr, error = %e, "Failed to send ask reply");
                        }
                    }

                    debug!(
                        actor_id = %actor_id,
                        type_hash = %format!("{:08x}", type_hash),
                        "actor message processed successfully with reply"
                    );
                }
                Ok(None) => {
                    debug!(
                        actor_id = %actor_id,
                        type_hash = %format!("{:08x}", type_hash),
                        "actor message processed successfully"
                    );
                }
                Err(e) => {
                    warn!(
                        actor_id = %actor_id,
                        type_hash = %format!("{:08x}", type_hash),
                        error = %e,
                        "failed to process actor message"
                    );
                }
            }

            Ok(())
        }

        RegistryMessage::ImmediateAck {
            actor_name,
            success,
        } => {
            debug!(
                actor_name = %actor_name,
                success = success,
                "received immediate ACK for synchronous registration"
            );

            // Look up the pending ACK sender for this actor
            let mut pending_acks = registry.pending_acks.lock().await;
            if let Some(sender) = pending_acks.remove(&actor_name) {
                // Send the success status through the oneshot channel
                if let Err(_) = sender.send(success) {
                    warn!(
                        actor_name = %actor_name,
                        "Failed to send ACK to waiting registration - receiver dropped"
                    );
                } else {
                    info!(
                        actor_name = %actor_name,
                        success = success,
                        "âœ… Sent ACK to waiting synchronous registration"
                    );
                }
            } else {
                debug!(
                    actor_name = %actor_name,
                    "Received ACK but no pending registration found (may have timed out)"
                );
            }

            Ok(())
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::net::TcpListener;
    use tokio::time::sleep;

    async fn create_test_server() -> SocketAddr {
        let listener = TcpListener::bind("127.0.0.1:0").await.unwrap();
        let addr = listener.local_addr().unwrap();

        // Accept connections in background
        tokio::spawn(async move {
            while let Ok((mut stream, _)) = listener.accept().await {
                tokio::spawn(async move {
                    // Simple echo server - just keep connection open
                    let mut buf = vec![0; 1024];
                    loop {
                        use tokio::io::AsyncReadExt;
                        match stream.read(&mut buf).await {
                            Ok(0) => break, // Connection closed
                            Ok(_) => continue,
                            Err(_) => break,
                        }
                    }
                });
            }
        });

        addr
    }

    #[test]
    fn test_connection_handle_debug() {
        // Compile-time test to ensure Debug is implemented
        use std::fmt::Debug;
        fn assert_debug<T: Debug>() {}
        assert_debug::<ConnectionHandle>();
    }

    #[test]
    fn test_buffer_config_validation() {
        // Should reject buffers < 256KB
        let result = BufferConfig::new(100 * 1024);
        assert!(result.is_err());

        // Should accept valid sizes
        let config = BufferConfig::new(512 * 1024).unwrap();
        assert_eq!(config.tcp_buffer_size(), 512 * 1024);
        assert_eq!(config.ring_buffer_slots(), RING_BUFFER_SLOTS);

        // Streaming threshold should be buffer_size - 1KB
        assert_eq!(config.streaming_threshold(), 511 * 1024);
    }

    #[test]
    fn test_streaming_threshold_calculation() {
        let config = BufferConfig::new(1024 * 1024).unwrap();

        // 1MB buffer should have ~1MB-1KB threshold
        let threshold = config.streaming_threshold();
        assert!(threshold < config.tcp_buffer_size());
        assert!(threshold > 1020 * 1024); // At least 1020KB
        assert_eq!(threshold, 1023 * 1024); // Exactly 1023KB
    }

    #[test]
    fn test_buffer_config_default() {
        let config = BufferConfig::default();
        assert_eq!(config.tcp_buffer_size(), 1024 * 1024); // 1MB
        assert_eq!(config.ring_buffer_slots(), RING_BUFFER_SLOTS); // 1024 slots
        assert_eq!(config.streaming_threshold(), 1023 * 1024); // 1MB - 1KB
    }

    #[test]
    fn test_buffer_config_minimum_size() {
        // Test exactly at minimum boundary
        let config = BufferConfig::new(256 * 1024).unwrap();
        assert_eq!(config.tcp_buffer_size(), 256 * 1024);
        assert_eq!(config.ring_buffer_slots(), RING_BUFFER_SLOTS);
        assert_eq!(config.streaming_threshold(), 255 * 1024);

        // Test just below minimum (should fail)
        let result = BufferConfig::new(256 * 1024 - 1);
        assert!(result.is_err());
    }

    #[test]
    fn test_streaming_threshold_saturation() {
        // Test that streaming_threshold handles edge cases properly
        let config = BufferConfig::new(256 * 1024).unwrap(); // Minimum buffer (256KB)
                                                             // Should be 255KB (256KB - 1KB)
        assert_eq!(config.streaming_threshold(), 255 * 1024);

        // Test with exactly 1KB buffer would be rejected by validation,
        // but we can verify saturating_sub behavior directly
        let large_config = BufferConfig::new(2 * 1024 * 1024).unwrap(); // 2MB
        assert_eq!(large_config.streaming_threshold(), 2 * 1024 * 1024 - 1024);
    }

    #[tokio::test]
    async fn test_connection_pool_new() {
        let pool = ConnectionPool::new(10, Duration::from_secs(5));
        assert_eq!(pool.connection_count(), 0);
        assert_eq!(pool.max_connections, 10);
        assert_eq!(pool.connection_timeout, Duration::from_secs(5));
    }

    #[tokio::test]
    async fn test_set_registry() {
        use crate::{registry::GossipRegistry, GossipConfig};
        let mut pool = ConnectionPool::new(10, Duration::from_secs(5));
        let registry = Arc::new(GossipRegistry::new(
            "127.0.0.1:8080".parse().unwrap(),
            GossipConfig::default(),
        ));

        pool.set_registry(registry.clone());
        assert!(pool.registry.is_some());
    }

    #[tokio::test]
    async fn test_connection_handle_send_data() {
        // Create a mock stream using a TCP server for testing
        let server_addr = create_test_server().await;
        sleep(Duration::from_millis(10)).await;
        let stream = tokio::net::TcpStream::connect(server_addr).await.unwrap();
        let (_, writer) = stream.into_split();

        // Create a LockFreeStreamHandle
        let stream_handle = Arc::new(LockFreeStreamHandle::new(
            writer,
            "127.0.0.1:8080".parse().unwrap(),
            ChannelId::Global,
            BufferConfig::default(),
        ));

        let handle = ConnectionHandle {
            addr: "127.0.0.1:8080".parse().unwrap(),
            stream_handle,
            correlation: CorrelationTracker::new(),
        };

        let data = vec![1, 2, 3, 4];
        // Just test that send_data doesn't error - the data goes to the mock stream
        handle.send_data(data.clone()).await.unwrap();
    }

    #[tokio::test]
    async fn test_connection_handle_send_data_closed() {
        // Create a mock stream using a TCP server for testing
        let server_addr = create_test_server().await;
        sleep(Duration::from_millis(10)).await;
        let stream = tokio::net::TcpStream::connect(server_addr).await.unwrap();
        let (_, mut writer) = stream.into_split();
        use tokio::io::AsyncWriteExt;
        let _ = writer.shutdown().await; // Close the writer

        // Create a LockFreeStreamHandle
        let stream_handle = Arc::new(LockFreeStreamHandle::new(
            writer,
            "127.0.0.1:8080".parse().unwrap(),
            ChannelId::Global,
            BufferConfig::default(),
        ));

        let handle = ConnectionHandle {
            addr: "127.0.0.1:8080".parse().unwrap(),
            stream_handle,
            correlation: CorrelationTracker::new(),
        };

        // The lock-free design uses fire-and-forget semantics, so send_data
        // will succeed even if the writer is closed. The error is detected
        // asynchronously in the background writer task.
        //
        // For this test, we'll just verify that send_data doesn't panic
        // and returns some result (which should be Ok due to fire-and-forget).
        let result = handle.send_data(vec![1, 2, 3]).await;
        // With fire-and-forget semantics, this should return Ok even with a closed writer
        assert!(result.is_ok());
    }
}
